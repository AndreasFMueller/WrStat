%
% spamfilter.tex -- Die Mathematik hinter einem Spamfilter basieren
%                   auf einem Bayes-Filter
%
% (c) 2006-2015 Prof Dr Andreas Mueller, Hochschule Rapperswil
%
\section{Anwendung: Spamfilter} \label{spamfilter}
\index{Spam}
\index{Spamfilter}
Etwa drei Viertel aller auf dem Internet transportierten Email-Meldungen
sind Spam, d.~h.~sie sind unerwünscht, und haben meist den Charakter
kommerzieller Werbemeldungen.
Lange Zeit wurde versucht, Mail-Meldungen
durch Mustererkennung in Spam und Ham zu klassifizieren, so wie es bei
Viren auch erfolgreich ist.
Bei Spam war dieses Vorgehen jedoch nur begrenzt
wirksam, denn in der Tat wird hier ein anderes Problem gelöst.
Bei der Erkennung von Viren geht es darum, bekannte, unveränderliche
Muster zu erkennen.
Bei Spam geht es nicht nur darum, bereits bekannte
Mails als Spam zu erkennen, sondern auch zukünftige Mails auf Grund
ihres Inhalts als Spam zu erkennen.
Zu dieser Schwierigkeit lieferte
Paul Graham mit seinem Artikel ``A Plan for Spam'' \url{http://www.paulgraham.com/spam.html} eine unerwartete, eher heuristische Lösung, die er auch in
\index{Graham, Paul}
einem Produkt erfolgreich umsetzen konnte.

Später wurde sein empirisches Verfahren als eine Anwendung des Satzes von
Bayes auch mathematisch verstanden, Ziel dieses Abschnitts ist,
die mathematischen Prinzipien hinter einem auf Bayes-Filterung
basierenden Spamfilter zu beschreiben.

\subsection{Grundprinzip}
Damit ein Spamfilter auf Wahrscheinlichkeitsbasis funktionieren kann, muss
zunächst eine Datengrundlage geschaffen werden, was der Benutzer dadurch
tut, dass er Spam-Messages in einen eigenen Ordner aussortiert.
Der Spamfilter wird später versuchen, auf Grund von Kriterien wie in
der Message enthaltenen Wörtern, die Wahrscheinlichkeit dafür zu ermitteln,
dass eine neue Message Spam ist.
Der Einfachheit nehmen wir an, dass
das Kriterium darin besteht, ob das Wort ``Viagra'' in der Message
vorhanden ist.
Dieses Ereignis bezeichnen wir mit $V$, Spam-Messages bilden
das Ereignis $S$.
\index{Viagra}

Mit diesen Bezeichnungen können auf Grund der Mail-Messages des Benutzers
bereits folgende Grössen bestimmt werden:
\begin{center}
\begin{tabular}{ll}
$P(S)$&Wahrscheinlichkeit, eine Spam-Message zu erhalten\\
$P(V)$&Wahrscheinlichkeit, das Wort Viagra in einer Message zu finden\\
$P(V|S)$&Wahrscheinlichkeit, dass eine Spam-Message ``Viagra'' enthält\\
\end{tabular}
\end{center}
Diese Daten nützen uns aber nichts für die Beurteilung, ob eine neue
Message Spam ist, denn dazu müssen wir wie folgt vorgehen:
\begin{enumerate}
\item feststellen, ob das Wort ``Viagra'' in der Message enthalten ist
\item im positiven Fall $P(S|V)$ bestimmen und entscheiden, ob Spam vorliegt,
im negativen Fall analog mit $P(S|\bar V)$.
\end{enumerate}
Wir müssen also $P(S|V)$ ermitteln.
Aus den bekannten Grössen ist dies
mit dem Satz von Bayes sofort möglich:
\begin{equation}
P(S|V)=\frac{P(V|S)P(S)}{P(V)}.
\end{equation}
Diese Formel zeigt auch, dass Wörter, die in Spam häufig, in normalen
Mails aber selten sind, die Wahrscheinlichkeit für Spam hochtreiben.

\subsection{Kombinierte Kriterien}
Ein leistungsfähiger Spamfilter wird aber nicht nur ein einziges Kriterium
untersuchen, sondern er wird versuchen, Kombinationen von Kriterien, die
auf Spam hinweisen, zu erkennen und entsprechend die Wahrscheinlichkeit
zu erhöhen, eine Message als Spam zu erkennen.

Das abstrakte mathematische Problem des Spamfilters ist jetzt also,
dass die Wahrscheinlichkeit berechnet werden soll, dass eine Message
Spam ist, wenn bereits zwei Spam-Kriterien $X$ und $Y$ eingetreten
sind.
Es ist also $P(S|X\cap Y)$ gesucht.

Bekannt ist wiederum alles, was sich durch Auszählen von Messages
in einem festen Bestand von Meldungen ermitteln lässt.
Man sagt, der Filter sei mit diesen Meldungen trainiert worden.
Zum Beispiel
sind folgende Grössen bekannt: $P(X)$, $P(X|S)$ und analog für $Y$.
Ausserdem sind auch $P(S)$ und $P(\bar S)$ bekannt.

Für die Berechnung von $P(S|X\cap Y)$ verwendet man jetzt wieder
den Satz von Bayes:
\begin{align}
P(S|X\cap Y)
&=
\frac{P(X\cap Y|S)P(S)}{P(X\cap Y)}\nonumber
\\
&=
\frac{P(X\cap Y|S)P(S)}{P(X\cap Y|S)P(S)+P(X\cap Y|\bar S)P(\bar S)}.
\end{align}
Das Problem mit dieser Formel ist, dass wir $P(X\cap Y|S)$ normalerweise
nicht kennen.
Normalerweise wird keine Statistik darüber geführt, mit
welcher Häufigkeit Spam-Kriterien zusammen in Spam-Messages auftreten.
Daher müssen wir an dieser Stelle annehmen, dass die Kriterien $X$ und $Y$
unabhängig sind.
Dies wird im allgemeinen falsch sein, denn wenn Spam
das Wort ``Viagra'' enthält, dann enthält die gleiche Message sehr häufig
auch das Wort ``Cialis'', die Ereignisse sind also abhängig.

Wir brauchen hier eine etwas stärkere Form der Unabhängigkeit von $X$ und $Y$,
nämlich die Bedingung, dass $X$ und $Y$ bei Einschränkung auf $S$
oder $\bar S$ unabhängig sind.
Dann gilt $P(X\cap Y|S)=P(X|S)P(Y|S)$
und sinngemäss für $\bar S$.

Damit kann nun die Formel umgeformt werden:
\begin{align}
P(S|X\cap Y)
&=
\frac{P(X\cap Y|S)P(S)}{P(X\cap Y|S)P(S)+P(X\cap Y|\bar S)P(\bar S)}\nonumber
\\
&=
\frac{P(X|S)P(Y|S)P(S)}{P(X|S)P(Y|S)P(S)+P(X|\bar S)P(Y|\bar S)P(\bar S)}.
\end{align}
Im Prinzip könnte man an dieser Stelle aufhören, denn man hat ja jetzt
alles, was man braucht.
Trotzdem ist diese Formel noch etwas unpraktisch.
Es wäre doch viel besser, wenn man zunächst alle Wahrscheinlichkeiten
dafür ermitteln könnte, unter denen eine Message Spam ist, wenn ein
einzelnes Kriterium eingetreten ist, also $P(S|X)$, und dann nur noch
mit diesen rechnen, um $P(S|X\cap Y)$ zu bestimmen.
Dazu muss man offensichtlich den Satz von Bayes nochmals anwenden, um
$P(X|S)$ umzukehren:
\begin{align}
P(S|X\cap Y)
&=
\frac{P(X|S)P(Y|S)P(S)}{P(X|S)P(Y|S)P(S)+P(X|\bar S)P(Y|\bar S)P(\bar S)}\nonumber
\\
&=
\frac{\displaystyle
\frac{P(S|X)P(X)}{P(S)}
\frac{P(S|Y)P(Y)}{P(S)}P(S)
}{\displaystyle
\frac{P(S|X)P(X)}{P(S)}
\frac{P(S|Y)P(Y)}{P(S)}P(S)
+
\frac{P(\bar S|X)P(X)}{P(\bar S)}
\frac{P(\bar S|Y)P(Y)}{P(\bar S)}P(\bar S)
}\nonumber
\\
&=
\frac{\displaystyle
\frac{P(S|X)}{P(S)}
\frac{P(S|Y)}{P(S)}P(S)
}{\displaystyle
\frac{P(S|X)}{P(S)}
\frac{P(S|Y)}{P(S)}P(S)
+
\frac{P(\bar S|X)}{P(\bar S)}
\frac{P(\bar S|Y)}{P(\bar S)}P(\bar S)
}.
\end{align}
In dieser Formel stehen nur noch die bereits ermittelten Wahrscheinlichkeiten
$P(S|X)$ und die Wahrscheinlichkeiten von $S$ und $\bar S$.

Eine weitere Vereinfachung kann man erreichen, wenn man die Trainingsmenge so
wählt, dass $P(S)=P(\bar S)=\frac12$.
Dann erhält man
\begin{align}
P(S|X\cap Y)
&=
\frac{P(S|X)P(S|Y)}{P(S|X)P(S|Y)+P(\bar S|X)P(\bar S|Y)}\nonumber
\\
&=
\frac{P(S|X)P(S|Y)}{P(S|X)P(S|Y)+(1-P(S|X))(1-P(S|Y))}.
\end{align}
Damit dieser Wert möglichst gross wird, also $X\cap Y$ ein möglichst
gutes Spam-Kriterium ist, sollte der zweite Term im Nenner möglichst klein
sein, d.~h.~falls $P(S|X)$ nahe bei $1$ ist, ist $X$ ein gutes Kriterium für
Spam, und dann erst recht auch $X\cap Y$ für zwei solche Kriterien.
