%
% generatoren.tex -- kurze beschreibung verschiedener Zufallszahlgeneratoren
%
% (c) 2006-2015 Prof Dr Andreas Mueller, Hochschule Rapperswil
%
\rhead{Zufallszahlgeneratoren}
\chapter{Zufallszahlgeneratoren}
Computer als deterministische Maschinen können grundsätzlich keine
echten Zufallszahlen erzeugen.
Aber durch geeignete Methoden kann man
wenigstens Zahlfolgen erzeugen, welche 
\begin{enumerate}
\item gleichmässig verteilt sind, und für die es
\item ohne Kenntnis des Maschinenzustandes
sehr schwer ist, die nächste Zahl in der Folge vorherzusagen.
\end{enumerate}
Für einfache Simulationen ist vor allem die erste Bedingung wichtig.
Wenn Zufallszahlen jedoch zur Schlüsselgenerierung benötigt werden,
wäre ein Versagen bei Bedingung 2 katastrophal.

Das Interesse an computererzeugten Zufallszahlen begann kurz nach dem
Erscheinen der erstem Computer.
John von Neumann schlug 1946
vor, Zufallszahlen durch Quadrieren zu bilden.
Wenn zum Beispiel
der Vorgängerwert 1234554321 ist, wird dies Zahl quadriert, was
1524124371499771041 ergibt, und dann die mittleren 10 Stellen
daraus entnommen, also 1243714997.
Dieser Prozess kann offensichtlich
beliebig oft wiederholt werden, und liefert zehnstellige Zahlen, die
schwer vorherzusagen sind, die Folge scheint zufällig zu sein.

Weitere Untersuchungen haben dann gezeigt, dass dieser Zufallszahlgenerator
ziemlich schlecht ist.
Es scheint nicht so einfach zu sein, zufällige
Zahlen zu erzeugen, auch sehr komplizierte Programme haben die Tendenz,
Zahlfolgen mit erkennbarer Gesetzmässigkeit zu erzeugen.

Eine Referenz zum Thema dieses Abschnitts ist \ref{knuth-taocp2}.

\section{Erzeugen}
\subsection{Lineare Kongruenzen}
Einer der ältesten Algorithmen zur Erzeugung von Pseudozufallszahlen
wure von D.~H.~Lehmer 1949 vorgeschlagen.
Er konstruiert eine Zahlenfolge
$(X_k)_{k\in\mathbb{N}}$
wie folgt.
\begin{definition}
Geeben seien drei natürliche Zahlen $m>0$, der Modulus, $a < m$, der
Multiplikator, und $c< m$, das Inkrement.
Dann definiert jeder Startwert
$X_0<m$ eine Folge $(X_k)_{k\in\mathbb{N}}$ durch
\begin{equation}
X_{n+1}=(aX_n+c)\mod m,\quad\text{$n\ge 0$}.
\end{equation}
Diese Folge heisst die durch $m$, $a$, $c$ und $X_0$ definierte Folge
linearer Kongruenzen.
\end{definition}
Natürlich wird $0\le X_n <m$ gelten für alle $n$, und damit
werden sich die Zahlen auch spätestens nach $m$ Werten zu wiederholen
beginnen, manchmal auch schon bedeutend früher.
Eine Auskunft darüber, ob diese maximal mögliche Periode erreicht wird,
gibt der folgende Satz.

\begin{satz}
Die durch $m$, $a$, $c$ und $X_0$ definierte Folge linearer Kongruenzen
hat Periodenlänge $m$ genau dann wenn
\begin{enumerate}
\item $c$ ist relativ prim zu $m$
\item $b=a-1$ ist ein Vielfaches von $p$ für jede Primzahl $p$, die $m$
teilt.
\item $b$ ist ein Vielfaches von 4, falls $m$ ein Vielfaches von 4 ist.
\end{enumerate}
\end{satz}

Besonders interessant für die Implementation auf einem Computer ist die
Wahl $m=2^e$.
In diesem Fall sind $a$ und $c$ ungerade zu wählen, womit
bereits die ersten beiden Bedingungen des Satzes erfüllt sind.
Wenn
$a$ ausserdem Rest 1 hat bei Teilung durch 4, ist auch die dritte Bedingung
erfüllt.
Mit $m=8$, $c=7$ und $a=5$ ist die von $X_0=0$ erzeugte Folge:
\[
 0, 7, 2, 1, 4, 3, 6, 5, 0, 7, 2, 1, 4, 3, 6, 5, 0, \dots
\]

\subsection{Schieberegisterfolgen}
Lineare Kongruenzen sind für geeignet grosse Werte von $m$ durchaus
angemessen
zufällig, aber natürlich für kryptographische Anwendungen immer noch
absolut unbrauchbar.
Es sind viele Varianten des Lehmerschen Algorithmus
untersucht worden, grundsätzlich ist es aber nicht möglich, eine längere
Periode als $m$ zu erzeugen.
Dazu wäre es nötig, nicht nur den
vorangegangenen Wert $X_n$ in die Berechnung von $X_{n+1}$ einfliessen
zu lassen, sonderen auch $X_{n-1}$ oder noch frühere Werte.
Der folgende
Algorithmus stammt von G.~J.~Mitchell und D.~P.~Moore.
Er geht von
zufälligen Startwerten $X_0,\dots X_{54}$ aus und definiert
\begin{equation}
X_n=(X_{n-24}+X_{n-55})\mod m.
\end{equation}
Die Zahlen 24 und 55 sind nicht zufällig, sondern wurden so gewählt,
dass das niedrigste Bit von $X_n$ eine Periode von $2^{55}-1$ hat.

Seit der Entdeckung dieses Zufallszahlgenerators sind auch andere Paare
als $(25,55)$ gefunden worden, die der erzeugten Zahlfolge ebenso gute
Eigenschaften  verleihen.

\subsection{Kombination von Zufallsfolgen}
Aus zwei Zufallsfolgen $(X_n)_{n\in\mathbb{N}}$ und $(Y_n)_{n\in\mathbb{N}}$
kann man durch 
\begin{equation}
Z_n=(X_n+Y_n)\mod m
\end{equation}
eine neue Zufallsfolge bilden.
Deren Periode kann viel länger sein als die
Perioden von $X_n$ und $Y_n$, falls diese verschieden sind.

Man kann auch eine Folge $X_n$ noch etwas aufmischen, bevor man sie ausgibt,
und so die Periode vergrössern.
Dazu speichert man die ersten $k$
Werte $X_0,\dots X_{k-1}$ in Speicherstellen $V_0,\dots V_{k-1}$.
Ausserdem
verwendet man die Hilfsvariable $Y$, die man mit $X_k$ initialisiert.
Nun wendet man folgenden Algorithmus auf $V$ und $Y$ an:
\begin{enumerate}
\item $j = \lfloor kY/m\rfloor$, wobei $m$ der Modulus der Folge $X_n$ ist.
\item $Y = V_j$, gebe $Y$ aus und setze $V_j$ auf den nächsten Wert
in der Folge.
\end{enumerate}
Dieser Algorithmus stammt von Bays und Durham, er gibt die Zahlen der
Folge $X_n$ in geänderter Reihenfolge zurück.

\subsection{Kryptographische Zufallszahlen}
Die Anforderungen an Zufallszahlen, die in kryptographischen Anwendungen
benötigt werden, sind wie bereits erwähnt bedeutend höher.
Die Entwicklung
der nötigen Grundlagen zur Beschreibung dieser Zufallszahlgeneratoren
würde jedoch zu weit führen.

\section{Zufallszahlen mit einer bestimmten Verteilung}
Gemäss dem vorangehenden Abschnitt sind wir in der Lage, 
Zufallszahlen so zu erzeugen, dass sie in einem gegebenen Intervall
gleichverteilt sind.
Für die Simulation von Wahrscheinlichkeitsexperimenten
braucht man aber Zufallszahlen, die eine gegebene Verteilung haben.
Wie kann man aus gleichverteilten Zufallszahlen solche berechnen,
die einer bestimmten Verteilung genügen?

\subsection{Zufallszahlen mit Verteilungsfunktion \texorpdfstring{$F$}{F}}
Gegeben sei jetzt also eine Verteilungsfunktion $F$ mit
Wahrscheinlichkeitsdichte $\varphi$, und ausserdem ein Zufallszahlgenerator
$X$, also eine Zufallsvariable, mit gleichverteilten Werten im Intervall
$[0,1]$.
Gesucht ist eine Zufallsvariable $Y$, welche $F$ als
Verteilungsfunktion hat.
Der folgende Satz liefert eine
einfache und effiziente Lösung dieses Problems.

\begin{satz}Ist $X$ gleichverteilt im Intervall $[0,1]$, und $F$ eine
invertierbare
Verteilungsfunktion, dann ist $F^{-1}\circ X$ eine Zufallsvariable
mit Verteilungsfunktion $F$.
\end{satz}
\begin{proof}[Beweis]
Wir berechnen die Verteilungsfunktion von $F^{-1}\circ X$ mit Hilfe
der Definition:
\begin{equation}
P(Y\le y)=P(F^{-1}\circ X\le y)=P(X\le F(y))=F(y).
\end{equation}
Das letzte Gleichzeitszeichen verwendet die Verteilungsfunktion der 
Gleichverteilung im Intervall: $P(x\le m)=m$.
\end{proof}

Im Allgemeinen wird eine Verteilungsfunktion nicht invertierbar sein.
Trotzdem ist es möglich, $Y$ so zu wählen, dass es $F$ als
Verteilungsfunktion hat.
Man möchte erreichen, dass $P(Y\le y)=F(y)
=P(X\le F(y))$, d.~h.~man $Y$ so wählen, dass $Y\le y$ genau dann wenn
$X\le F(y)$.
Dies erreicht man offenbar mit
\begin{equation}
Y(x)=\min_{F(\eta)\ge x}\eta,
\end{equation}
denn dies bedeutet, dass
\begin{equation}
Y\le y\qquad\Leftrightarrow\qquad
F(\eta)\ge x\quad\text{für alle}\quad \eta>y
\end{equation}
Da $F$ rechtsseitig stetig ist, ist die letzte Bedingung gleichbedeutend
mit $F(y)\le x$.
Somit hat man den allgemeineren Satz
\begin{satz}
Ist $X:\Omega\to\mathbb{R}$ eine im Intervall $[0,1]$
gleichverteilte Zufallsvariable,
und $F$ eine Verteilungsfunktion, dann definiert die Abbildung
\begin{equation}
Y\colon\Omega\to\mathbb{R}\colon \omega\mapsto \min\{\eta\,|\,F(\eta)\ge X(\omega)\}
\end{equation}
eine Zufallsvariable mit Verteilungsfunktion $F$.
\end{satz}
Die so konstruierte Funktion
\begin{equation}
G\colon\mathbb{R}\to\mathbb{R}\colon x\mapsto\min\{\eta\,|\,F(\eta)\ge x\}
\end{equation}
kann als eine verallgemeinerte Umkehrfunktion betrachtet werden.
Für invertierbare Funktionen $F$ stimmt sie mit $F^{-1}$ überein.

Zunächst ist $G$ wie $F$ eine monotone Funktion.
Ist die Funktion $F$ in einem Intervall konstant, dann lässt sich ein maximales
Intervall $[a,b)$ finden, in dem $F$ konstant ist.
Für alle $x\in[a,b)$ gilt dann
\begin{equation}
G(F(x))=\min\{\eta\,|\,F(\eta)\ge F(x)\}=\min[a,\infty)=a.
\end{equation}
Für $y\ge F(x)$ gilt
\begin{equation}
G(y)=\min\{\eta\,|\,F(\eta)\ge y\}\ge b,
\end{equation}
Die Funktion $G$ hat als an der Stelle $F(x)$ einen Sprung, sie ist dort
wie eben gezeigt wurde linksseitig stetig.

Sei umgekehrt $x$ eine Sprungstelle von $F$, dann werden die
Werte $(F(x+),F(x))$ nicht angenommen.
Für ein $y\in(F(x+),F(x))$
gilt dann
\begin{equation}
G(y)=\min\{\eta\,|\,F(\eta)\ge y\}=\min\{\eta\,|\,F(\eta)\ge F(x)\}=x,
\end{equation}
die Funktion $G$ ist also auf dem Intervall $(F(x+),F(x))$ konstant.

\subsection{Gleichverteilte Zufallszahlen} \label{gleichverteilte-zufallszahlen}
Umgekehrt ist es interessant, wenn man eine Zufallsvariable so transformieren
kann, dass sie eine bestimmte Verteilung bekommt.
Dies ist zum 
Beispiel nützlich, wenn man die Qualität eines Zufallszahlgenerators
testen will.
Verspricht der Zufallszahlgenerator, Zufallszahlen $X_i$ zu
produzieren, die einer Verteilung mit Verteilungsfunktion $F$
genügen, dann sind nach Satz \ref{reduktion-auf-gleichverteilung} die
$F(X_i)$ im Intervall $[0,1]$ gleichverteilte Zufallszahlen.

\section{Testen}
Nachdem wir nun einige Verfahren kennen, mit denen Zufallszahlen
erzeugt werden können, stellt sich automatisch die Frage, welches
den für einen bestimmten Anwendungszweck geeignet ist.
Dabei spielen auch Aspekte eine Rolle, die nicht Gegenstand der
Wahrscheinlichkeitsrechnung sind, zum Beispiel der Rechenaufwand
zur Bestimmung einer grossen Zahl von Zufallswerten, oder die Periode
des Zufallszahlgenerators, welcher in den Diskussionen des vorangegangenen
Abschnitts ja bereits Platz eingeräumt worden ist.

In diesem Abschnitt interessieren jedoch nur die statistischen Eigenschaften
von Zufallszahlgeneratoren, zum Beispiel möchte man die Verteilung
der Zufallszahlen kennen.
In Simulationen benötigt man Zufallsereignisse mit einer bestimmten
Verteilung.
Um zum Beispiel Diffusion oder Brownsche Bewegung in
zu beschreiben, muss man normalverteilte Zufallszahlen bekommen
können, Um den Ausfall von Komponenten eines Systems zu simulieren,
braucht man exponentialverteilte Zufallszahlen.
Im einfachsten Fall,
der zum Beispiel auch bei Spielen meistens vorkommt, verlangt man
auf einem Intervall gleichverteilte Zufallszahlen.

Die meisten Generatoren des vorangegangenen Abschnitts
liefern ganze Zahlen eines Maschinentyps, also ganze Zahlen zwischen
$-M$ und $M$, wobei $M$ meistens eine grosse Zweierpotenz ist.
Durch eine lineare Transformation
\begin{equation}
x\mapsto \frac{x+M}{2M}(b-a) + a,
\end{equation}
welche in Gleitkommaarithmetik durchzuführen ist, erhält man
Zufallszahlen im Intervall $[a,b]$.
Wie kann man diese Hypothese testen?

Im Kapitel \ref{chapter-hypothesen-testen} hatten wir mit dem $\chi^2$-Test
und dem Kolmogorov-Smirnov-Test zwei Verfahren kennengelernt, mit denen
man testen kann, ob eine Stichprobe (also eine Teilfolge der Zufallsfolge
des Generators) einer bestimmten Verteilung genügt.
Im vorliegenden Fall
ist gefordert, dass die Zufallszahlen in einem Intervall gleichverteilt
sein sollen, wofür sich sowohl der $\chi^2$-Test wie auch der
Kolmogorov-Smirnov-Test eignen.
Haben die Zufallszahlen eine beliebige
andere Verteilung mit Verteilungsfunktion $F$, kann dazu immer noch
der Kolmogorov-Smirnov-Test verwendet werden, oder es wird die Zufallsfolge
nach Abschnitt \ref{gleichverteilte-zufallszahlen} erst auf eine
Gleichverteilung transformiert.

\subsection{Lokale Tests}
Die eben beschriebenen Tests für Gleichverteilung sind nicht in der
Lage, lokale Regelmässigkeiten zu erkennen.
Gibt der Zufallszahlgenerator
zum Beispiel jede Zahl zweimal aus, dann führt dies immer noch zu
einer gleichmässigen Verteilung, aber man würde das wohl kaum als
Zufallsverhalten bezeichnen.
Daher müssen die Tests verfeinert werden,
um lokale Regelmässigkeiten für die Tests sichtbar zu machen.

\subsubsection{Paartest}
Beim Paartest wird aus jeweils zwei aufeinanderfolgenden Zahlen aus der
Zufallsfolge ein Paar gebildet.
Falls die Zufallsfolge $d$ verschiedene
Werte liefert, gibt es $d^2$ verschiedene mögliche Paare, die alle
mit gleicher Wahrscheinlichkeit vorkommen sollten.
Dies kann man mit einem
$\chi^2$-Test für die Verteilung der Paare überprüfen.

\subsubsection{Pokertest}
\begin{table}
\begin{center}
\begin{tabular}{|c|l|c|}
\hline
$r$&Beschreibung&$p_r$\\
\hline
$1$&fünf gleiche&$\frac{d}{d^5}=\frac1{d^4}$\\
$2$&Full house, vier gleiche&$ $\\
$3$&zwei paare, drei gleiche&$ $\\
$4$&ein paar&$ $\\
$5$&alle verschieden&Ã$\frac{5!}{d^5}$\\
\hline
\end{tabular}
\end{center}
\caption{Quintupel mit $r$ verschiedenen Werten und ihre Wahrscheinlichkeit}
\end{table}
Der Pokertest führt den Paartest noch etwas weiter.
Er bildet aus jeweils
fünf Zahlen der Zufallsfolge ein ``Blatt'', und fragt danach, wie häufig
in solchen Fünftupeln gewisse Konfigurationen vorkommen.
Im Poker
unterscheidet man sieben verschiedene Muster: alle verschieden, ein Paar,
zwei Paare, drei gleiche, full house, vier gleiche, fünf
gleiche\footnote{Tatsächlich kennt das Pokerspiel natürlich noch weitere
Konfigurationen, die kleine und grosse Strasse sind Fälle, wo alle fünf
Karten verschieden sind, diese sind jedoch für unsere Tests nicht
interessant.}.
Für die praktische Durchführung der Tests ist es jedoch
einfacher, nur die Anzahl $r$ der verschiedenen Werte in einem Fünftupel
anzusehen.
Ist die Zufallsfolge gleichverteilt, müssen $r$ verschiedene
mit den Wahrscheinlichkeiten $p_r$ auftreten, was sich mit Hilfe eines
$\chi^2$ Tests prüfen lässt.

\subsubsection{Maximum von \texorpdfstring{$t$}{t}}
In diesem Test bildet man aus $t$ Zufallsvariablen
$X_0,X_1,\dots,X_{j-1}$ eine neue Zufallsvariable
\begin{equation}
Y=\max(X_0,X_1,\dots,X_{j-1},
\end{equation}
und überprüfen mit dem Kolmogoroff-Smirnov-Test, ob $Y$ die richtige
Verteilung besitzt.
Dazu müssen wir die Verteilung von $Y$ kennen,
die folgenden Sätze geben dazu Auskunft.
\begin{satz}Sind $X$ und $Y$ unabh"nagige Zufallsvariable mit
Verteilungsfunktionen $F_X$ und $F_Y$, dann hat $\max(X,Y)$
die Verteilungsfunktion $F_XF_Y$ und $\min(X,Y)$ die Verteilungsfunktion
$F_X+F_Y-F_XF_Y$.
\end{satz}
\begin{proof}[Beweis]
Aus der Definition der Verteilungsfunktion folgt direkt
\begin{eqnarray}
F_{\max(X,Y)}(x)&=&P(\max(X,Y)\le x)\nonumber\\
&=&P(X\le x\wedge Y\le x)=P(X\le x)P(Y\le x)\nonumber\\
&=&F_X(x)F_Y(x)\\
F_{\min(X,Y)}(x)&=&P(\min(X,Y)\le x)\nonumber\\
&=&P(X\le x\vee Y\le x)=1-P(X>x\wedge Y>x)\nonumber\\
&=&1-(1-F_X(x))(1-F_Y(x))\nonumber\\
&=&F_X(x)+F_Y(x)-F_X(x)F_Y(x)
\end{eqnarray}
\end{proof}
Bei mehr als zwei Zufallsvariablen lassen sich entsprechende
Formeln angeben, wir interessieren uns jedoch nur für den Fall,
dass alle Zufallsvariablen die gleiche Verteilung haben, in dem
die Formeln besonders einfach werden.
\begin{satz}Sind $X_0,\dots,X_{j-1}$ unabhängige Zufallsvariable mit
gemeinsamer Verteilungsfunktion $F$.
Dann gilt
\begin{enumerate}
\item $Y=\max(X_0,\dots,X_{j-1})$ hat Verteilungsfunktion $F(x)^j$
\item $Z=\min(X_0,\dots,X_{j-1})$ hat Verteilungsfunktion $1-(1-F(x))^j$
\end{enumerate}
\end{satz}

\begin{proof}[Beweis]
Für $Y$ folgt aus der Definition sofort
\begin{equation}
P(Y\le x)=P(X_i\le x\forall i)=\prod_{i=0}^{j-1}P(X_i\le x)=F(x)^j.
\end{equation}
Entsprechend für $Z$
\begin{eqnarray}
P(Z\le x)&=&P(\exists i (X_i\le x)) = 1-P(X_i>x\forall i)\nonumber\\
&=&1-\prod_{i=0}^{j-1} P(X_i>x)\nonumber\\
&=&1-(1-F(x))^j
\end{eqnarray}
\end{proof}

Der Maximum-von-$t$ prüft einen Zufallszahlgenerator dadurch, dass
er jeweils von $t$ aufeinanderfolgenden Elementen der Zufallsfolge
das Maximum bildet und mit dem Kolmogorov-Smirnov-Test prüft,
ob die so entstandenen Zufallsvariable die Funktion $F(x)=x^t$ als
Verteilungsfunktion hat.
