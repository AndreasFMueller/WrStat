%SourceDoc ws-skript.tex
%
% wahrscheinlichkeit.tex -- 1. Kapitel, Wahrscheinlichkeitsbegriff
%
% (c) 2006-2015 Prof. Dr. Andreas Mueller, HSR
%
\rhead{Ereignisse und Wahrscheinlichkeit}
\chapter{Ereignisse und ihre Wahrscheinlichkeit} \label{chapter-ereignisse-und-wahrscheinlichkeit}

Es ist unm"oglich den Ausgang eines Sportwettkampfes vorauszusagen.
Trotzdem trauen sich viele Leute zu, auf Grund ihrer Kenntnisse "uber den
Trainingsstand der Sportler oder ihrer fr"uheren Leistungen,
Prognosen abzugeben.
Sie sind sich dabei oft so sicher, dass sie bereit sind, Geld auf ihren Tipp
zu wetten.
Eine solche Prognose ist nicht immer gleich schwierig. Wenn an der
Fussball WM der Favorit Brasilien gegen Ghana antritt,
rechnet wohl niemand ernsthaft mit einem Sieg Ghanas. Die Leute w"urden
sagen, es sei unwahrscheinlich, dass das Ereignis ``Ghana gewinnt'' eintreffen
w"urde. Anders sieht es aus, wenn die Schweiz auf die Ukraine trifft.
Die Prognosen "uber den Ausgang dieses Matches waren auch abseits
manchmal etwas chauvinistischer Hoffnungen mindestens uneinheitlich.

Wie auch immer, die einzige M"oglichkeit herauszufinden, welche Mannschaft
st"arker ist, besteht darin, das Spiel tats"achlich durchzuf"uhren.
Vorher w"urden wir einen Sieg der Schweizer Nati bestenfalls als
wahrscheinlich oder eher unwahrscheinlich einstufen.
Welche der beiden M"oglichkeiten tats"achlich eintritt, l"asst sich
erst nach dem Spiel sagen.

Wir haben also ein Ereignis, n"amlich einen Sieg der Schweizer Nati,
und sind mindestens gef"uhlsm"assig in der Lage, dem Eintreten dieses
Ereignis eine Wahrscheinlichkeit zuzuordnen.
Eine Sicherheit haben wir aber nicht. 
Dazu m"ussen wir das Experiment durchf"uhren, und sehen dann,
welches Ereignis, Sieg oder Niederlage eingetreten ist.

Die Wahrscheinlichkeitsrechnung will solchen Aussagen einen pr"azisen
mathematischen Sinn geben. Daher brauchen wir zun"achst Definitionen
f"ur die Begriffe ``Ereignis'' und ``Wahrscheinlichkeit''.  Mit geeigneten
Rechengesetzen sollte die Wahrscheinlichkeit berechnet werden k"onnen,
und wir sollten eine rationale Grundlage f"ur Sportwetten finden k"onnen.

\section{Versuche und Versuchsausg"ange}
Die Wahrscheinlichkeitsrechnung befasst sich also mit dem Ausgang von
Versuchen.
Das in der Einleitung beschriebene Fussballspiel ist ein solches Experiment.
Nat"urlich interessiert den Fussballfan viel mehr als das Ergebnis,
f"ur die Zwecke der Sportwetten gen"ugen jedoch die Schlussresultate.
"Ahnliche Experimente kann man sich in grosser Zahl ausdenken:
\begin{enumerate}
\item
\index{Munzwurf@M\"unzwurf}
Der Wurf einer M"unze ist ein Experiment mit, wenigstens
im Prinzip, drei Versuchsausg"angen: Kopf oder Zahl, ganz selten k"onnte
die M"unze auch auf der Kante stehen bleiben.
\item
\index{Wurfel@W\"urfel}
Ein weiteres Experiment ist der Wurf eines W"urfels. Klassische W"urfel
haben sechs Seitenfl"achen, die verschiedene Augenzahlen zeigen.
Nach jeder Durchf"uhrung des Experimentes zeigt der W"urfel ein neues
Resultat, das Experiment hat sechs verschiedene Ausg"ange.
\item
Der gleichzeitige Wurf zweier verschiedenfarbiger W"urfel ist ein Experiment
mit 36 verschiedenen m"oglichen Ausg"angen:
\begin{center}
\def\e#1#2{\epsdice[black]{#1}\,\epsdice{#2}}
\begin{tabular}{|c|cccccc|}
\hline
&\epsdice{1}&\epsdice{2}&\epsdice{3}&\epsdice{4}&\epsdice{5}&\epsdice{6}\\
\hline
\epsdice[black]{1}&\e{1}{1}&\e{1}{2}&\e{1}{3}&\e{1}{4}&\e{1}{5}&\e{1}{6}\\
\epsdice[black]{2}&\e{2}{1}&\e{2}{2}&\e{2}{3}&\e{2}{4}&\e{2}{5}&\e{2}{6}\\
\epsdice[black]{3}&\e{3}{1}&\e{3}{2}&\e{3}{3}&\e{3}{4}&\e{3}{5}&\e{3}{6}\\
\epsdice[black]{4}&\e{4}{1}&\e{4}{2}&\e{4}{3}&\e{4}{4}&\e{4}{5}&\e{4}{6}\\
\epsdice[black]{5}&\e{5}{1}&\e{5}{2}&\e{5}{3}&\e{5}{4}&\e{5}{5}&\e{5}{6}\\
\epsdice[black]{6}&\e{5}{1}&\e{6}{2}&\e{6}{3}&\e{6}{4}&\e{6}{5}&\e{6}{6}\\
\hline
\end{tabular}
\end{center}
\item 
Der gleichzeitige Wurf zweier ununterscheidbarer W"urfel ist ein 
ein ganz "ahnliches Experiment, aber die Zahl der Versuchsausg"ange
ist kleiner.
Da die W"urfel nicht unterscheidbar sind, kann man das Paar
\epsdice{5}\,\epsdice{6} nicht
vom Paar \epsdice{6}\,\epsdice{5} unterschieden.
Man kann beim Auflisten der Versuchsausg"ange die Paare immer aufsteigend
ordnen, es sind also nur die folgenden Versuchsausg"ange m"oglich:
\begin{center}
\def\e#1#2{\epsdice{#1}\,\epsdice{#2}}
\begin{tabular}{|c|cccccc|}
\hline
&\epsdice{1}&\epsdice{2}&\epsdice{3}&\epsdice{4}&\epsdice{5}&\epsdice{6}\\
\hline
\epsdice{1}&\e{1}{1}&\e{1}{2}&\e{1}{3}&\e{1}{4}&\e{1}{5}&\e{1}{6}\\
\epsdice{2}&        &\e{2}{2}&\e{2}{3}&\e{2}{4}&\e{2}{5}&\e{2}{6}\\
\epsdice{3}&        &        &\e{3}{3}&\e{3}{4}&\e{3}{5}&\e{3}{6}\\
\epsdice{4}&        &        &        &\e{4}{4}&\e{4}{5}&\e{4}{6}\\
\epsdice{5}&        &        &        &        &\e{5}{5}&\e{5}{6}\\
\epsdice{6}&        &        &        &        &        &\e{6}{6}\\
\hline
\end{tabular}
\end{center}
Es bleiben also nur noch 
\[
1+2+\dots +6=\sum_{i=1}^6=\frac{6\cdot(6+1)}2=21
\]
Versuchsausg"ange "ubrig.
Das heisst aber noch lange nicht, dass der Versuchsausgang
\epsdice{2}\,\epsdice{3} gleich wahrscheinlich ist wie 
\epsdice{3}\,\epsdice{3}, denn letzterer kann nur auf genau eine
Art entstehen, w"ahrend es f"ur \epsdice{2}\,\epsdice{3}
zwei M"oglichkeiten gibt.
\item 
Ein Gewitter tobt "uber einem Wald. 
Es ist m"oglich, dass ein Blitz in einen Baum einschl"agt,
die meisten B"aume werden jedoch verschont bleiben.
Wir k"onnen dieses Experiment zwar nicht jederzeit durchf"uhren,
aber wir k"onnen einfach auf das n"achste Gewitter warten.
Ist der Baum getroffen, k"onnen wir ihn auch nicht wieder verwenden,
aber wir k"onnen die Beobachtung an einem anderen, vergleichbaren
Baum wiederholen.
\item
\index{Ebola}
Menschen, die sich mit Ebola-Viren anstecken, sterben sehr h"aufig
an dieser Krankheit.
Auch hier liegt ein Experiment vor, welches wir nicht nach belieben
durchf"uhren d"urfen, doch wir k"onnen darauf warten, dass jemand
erkrankt, und dann vergleichbare Krankheitsf"alle untersuchen.
\item
Die Messung mit einem Messger"at ist ebenfalls ein wiederholbares
Experiment, der Versuchsausgang ist der vom Messger"at angezeigte
Messwert.
\end{enumerate}

Bevor also Aussagen "uber die Wahrscheinlichkeit gemacht werden k"onnen,
muss definiert werden, welches Experiment genau durchgef"uhrt worden ist.
Nur Experimente, die im Prinzip wiederholbar sind, sind der Untersuchung
durch die Wahrscheinlichkeitsrechnung zug"anglich.
Die Aussage: ``die Wahrscheinlichkeit, dass die Naturkonstanten des
Universums so sind, dass intelligentes Leben entstehen kann, ist\dots''
ist nicht nur deshalb Unsinn, weil wir nicht wissen, welche
Voraussetzungen zu intelligentem Leben f"uhren, sondern vor allem wegen
der Tatsache, dass wir keine anderen Universen zur Verf"ugung haben, in denen
wir die Frage nach intelligentem Leben erneut stellen k"onnten.

Ein logisches Argument kann nicht eine Wahrscheinlichkeit haben,
richtig oder falsch zu sein.
Ein Argument ist einfach richtig oder falsch.
Die Voraussetzungen f"ur das logische Argument sind vielleicht Beobachtungen
in der Natur, also Versuchsausg"ange anderer Experimente, und sie
k"onnen das Argument st"utzen, aber ein richtiges Argument wird nicht
falsch, wenn die Voraussetzungen nicht mehr erf"ullt sind, sondern einfach
nur nicht anwendbar.
Ein besonders krasses Beispiel f"ur v"olliges Unverst"andnis
dieser Grundtatsache ist die Conservapedia-Seite {\em Counterexamples
to an Old Earth}\footnote{\url{http://www.conservapedia.com/Counterexamples\_to\_an\_Old\_Earth}}.

F"ur die Zwecke der Wahrscheinlichkeitsrechnung ist der genaue Ablauf
eines Experimentes gegenstandslos, nur das Resultat interessiert.
Wir f"uhren daher die folgenden Begriffe in:

\begin{definition}
Der Ausgang eines Experimentes heisst {\em Elementarereignis}, die
Menge aller Elementarereignisse wird mit $\Omega$ bezeichnet.
Ein Elementarereignis $\omega$ ist also ein Element von $\Omega$,
$\omega\in\Omega$.
\index{Elementarereignis}
\end{definition}

Die Menge $\Omega$ der Elementarereignisse f"ur jedes der Beispiele weiter
oben ist:
\begin{enumerate}
\item $\Omega=\{\text{Kopf},\text{Zahl}\}$
\item $\Omega=\{\epsdice{1},
\epsdice{2},
\epsdice{3},
\epsdice{4},
\epsdice{5},
\epsdice{6}\}$
\item $\Omega$ besteht aus allen Paaren von Augenzahlen.
\item $\Omega$ besteht aus allen Paaren von Augenzahlen, in denen die
zweite Zahl mindestens so gross ist wie die erste:
{
\def\e#1#2{\epsdice{#1}\,\epsdice{#2}}
\def\p{\phantom{\epsdice{1}\,\epsdice{1},\,}}
\begin{align*}
\Omega=\{
           &\e{1}{1},\e{1}{2},\e{1}{3},\e{1}{4},\e{1}{5},\e{1}{6},\\
           &\p       \e{2}{2},\e{2}{3},\e{2}{4},\e{2}{5},\e{2}{6},\\
           &\p       \p       \e{3}{3},\e{3}{4},\e{3}{5},\e{3}{6},\\
           &\p       \p       \p       \e{4}{4},\e{4}{5},\e{4}{6},\\
           &\p       \p       \p       \p       \e{5}{5},\e{5}{6},\\
           &\p       \p       \p       \p       \p       \e{6}{6}
\}
\end{align*}
}
\item $\Omega=\{\text{Baum vom Blitz getroffen},\text{Baum verschont}\}$
\item $\Omega=\{\text{an Ebola gestorben},\text{Ebola "uberlebt}\}$
\item Die Menge der Elementarereignisse ist die Menge aller m"oglichen
Messwerte, also $\Omega=\mathbb{R}$ oder eine Teilmenge davon.
\end{enumerate}

\section{Ereignisalgebra} \label{section-ereignisse}
Die Modellierung von Versuchsausg"angen mit der Menge $\Omega$
allein ist nicht in der Lage, zus"atzliche Eigenschaften eines
Versuchsausgangs wiederzugeben.
Sie muss daher um den Begriff des Ereignisses erweitert werden.

\subsection{Ereignisse}
Oft sind die einzelnen Versuchsausg"ange nicht von Interesse.
Viele W"urfelspiele mit zwei W"urfeln haben besondere Regeln, wenn
der Spieler zwei gleiche Augenzahlen wirft, einen sogenannten {\em Pasch}.
Die Regeln sind unabh"angig vom Wert, es z"ahlt nur die Tatsache,
dass die beiden Augenzahlen gleich sind.
Das Ereignis ``Pasch'' ist eingetreten, wenn der Versuchsausgang, also das
Paar von Augenzahlen, in der Menge
\[
\def\e#1{\epsdice{#1}\,\epsdice{#1}}
P=\{
\e{1},
\e{2},
\e{3},
\e{4},
\e{5},
\e{6}
\}
\]
liegt.

Auch einzelne Messwerte sind oft nicht interessant. 
Ein "Uberspannungsereignis tritt zum Beispiel ein, wenn die Spannung
einen Wert "uberschreitet, oder wenn das Elementarereignis, also der Messwert,
in der Menge
\[
U=
\{x\in\mathbb R\,|\, x > x_{\text{Limite}}\}
\]
liegt.

Solche zusammengesetzten Ereignisse sind also immer Teilmengen von $\Omega$.
Wir k"onnen dies als eine Definition des Begriffs des Ereignisses
verwenden.

\begin{definition}
Ist $\Omega$ eine Menge von Versuchsausg"angen, dann heisst eine Teilmenge
$A\subset\Omega$ ein {\em Ereignis}.
Man sagt, das Ereignis $A$ ist {\em eingetreten}, wenn bei einer Durchf"uhrung des
Experimentes ein Versuchsausgang $\omega\in A$ aufgetreten ist.
\end{definition}

\begin{beispiel}
\begin{figure}
\centering
\includegraphics{images/ebola-1.pdf}
\caption{Ereignisse zum Experiment ``Person im Ebola-Gebiet''
\label{image-ebola}}
\end{figure}

In Abbildung~\ref{image-ebola} sind m"ogliche Ereignisse eines Experiments
dargestellt, bei dem ein zuf"allig ausgew"ahlte Person daraufhin untersucht
wurde, ob sie mit Ebola in Kontakt kam, daran erkrankte und inzwischen
verstorben ist.
Der einzelne Versuchsausgang ist also die Person, die f"ur die
Untersuchung ausgew"ahlt wurde. 
Die Menge $\Omega$ ist die Menge aller Personen.
Folgende Ereignisse wurden untersucht:
\begin{align*}
K&=\{\omega\in\Omega\,|\,\text{$\omega$ ist mit Ebola in Kontakt gekommen}\}
\\
E&=\{\omega\in\Omega\,|\,\text{$\omega$ ist an Ebola erkrankt}\}
\\
T&=\{\omega\in\Omega\,|\,\text{$\omega$ ist verstorben}\}
\end{align*}
Es gilt nat"urlich $E\subset K$, denn wer an Ebola erkrankt, muss mit
Ebola in Kontakt gekommen sein. 
Das umgekehrte gilt nicht, man kann durchaus mit Ebola in Kontakt
kommen, ohne daran zu erkranken.

Es gilt nicht, dass $E\subset T$, denn einerseits gibt es Personen, die
Ebola "uberlebt haben, und andererseits gibt es an Ebola erkrankte,
die zur Zeit des Experiments noch nicht verstorben sind.
Die Menge $E\cap T$ besteht aus denjenigen Personen, die an Ebola
erkrankt waren und verstorben sind.
Dies heisst aber nicht, dass sie an Ebola gestorben sind.
\end{beispiel}

Zwei Ereignisse $A$ und $B$ k"onnen bei der Durchf"uhrung des Experimentes
gleichzeitig eintreten.
Der Versuchsausgang $\omega$ ist also so beschaffen, dass mit ihm sowohl
$A$ als auch $B$ eintreten, dass also $\omega\in A$ und $\omega\in B$,
oder $\omega \in A\cap B$.
Gleichzeitigs Eintreten von Ereignis $A$ {\em und} $B$ ist das Ereignis
$A\cap B$.

Tritt ein Ereignis $A$ bei einer Versuchsdurchf"uhrung nicht ein, dann trat
ein Versuchsausgang $\omega$ auf, der nicht zu $A$ geh"ort,
also $\omega\in\Omega\setminus A$.
Dies bedeutet aber, dass das Ereignis $\Omega\setminus A=\overline{A}$
eingetreten ist.
Nichteintreten des Ereignisses $A$ ist das Ereignis
$\overline{A}=\Omega\setminus A$.

Zwei Ereignisse sind speziell.
Die Menge $\Omega\subset\Omega$ hat die Eigenschaft, dass jeder denkbare
Versuchsausgang per Definition in $\Omega$ liegt, das Ereignis $\Omega$
tritt also immer ein. $\Omega$ heisst daher auch das sichere Ereignis.
\index{Ereignis!sicheres}
Die leere Menge $\emptyset\subset\Omega$ hat genau die gegenteilige
Eigenschaft: was auch immer geschieht, was auch immer f"ur ein 
Elementarereignis $\omega$ realisiert wird, in $\emptyset$ kann es
nicht drin sein, also wird $\emptyset$ nie eintreten. $\emptyset$
heisst daher auch das unm"ogliche
Ereignis.
\index{Ereignis!unm\"ogliches}

Diese Beispiele zeigen, dass die Modellierung von Ereignissen als Teilmengen
von $\Omega$
mit der umgangsprachlichen Sprechweise von Ereignissen "ubereinstimmt.
Die Tabelle~\ref{begriffe-zusammenfassung}
fasst die gebr"auchlichsten Mengenoperationen und die zugeh"orige
Sprechweise f"ur Ereignisse zusammen.

\begin{table}
\begin{center}
\begin{tabular}{|l|c|}
\hline
Begriff&Modell\\
\hline
Elementarereignis&$\omega$\\
alle Elementarereignisse&$\Omega$\\
Ereignis&$A\subset\Omega$\\
sicheres Ereignis&$\Omega$\\
unm"ogliches Ereignis&$\emptyset$\\
$A$ und $B$&$A\cap B$\\
$A$ oder $B$&$A\cup B$\\
$A$ hat $B$ zur Folge, $A\Rightarrow B$&$A\subset B$\\
nicht $A$&$\Omega\setminus A$\\
\hline
\end{tabular}
\end{center}
\caption{Begriffe der Wahrscheinlichkeitstheorie und ihre mathematischen
Modellierung\label{begriffe-zusammenfassung}}
\end{table}

\subsection{Beispiele}
\subsubsection{AIDS-Test}
Wenn sich jemand im Bezug auf AIDS riskant verhalten hat, dann ist
eine seiner Sorgen, dass der AIDS-Test nicht sofort das richtige
Resultat anzeigt. Und selbst wenn er die notwendige Frist abgewartet
hat, hat der Test eine geringe Fehlerrate.
Es k"onnen also verschiedene Ereignisse eintreten. Meistens wird ein
positiver AIDS-Test richtig anzeigen, dass eine Person HIV hat. Manchmal
wird der Test jedoch positiv sein, obwohl die Person gesund ist. Und manchmal
wird der Test zwar ein positives Resultat zeigen, aber die Person ist
an HIV erkrankt. Gl"uck haben diejenigen, bei denen der Test nicht
anspricht, und die auch tats"achlich gesund sind.


\subsubsection{Euromillions}
\index{Euromillions}
\begin{figure}
\includegraphics[width=\hsize]{graphics/euromillions}
\caption{Besondere Gewinnchance in Euromillions}
\end{figure}
\begin{figure}
\begin{center}
\includegraphics[height=8cm]{graphics/euromillionsschein}
\end{center}
\caption{Teilnahmeschein f"ur Euromillions\label{euromillionsschein}}
\end{figure}
Am 5.~September 2008 schrieb die Gratiszeitung ``20 Minuten'', dass die
bevorstehende Ziehung der Lotterie Euromillions besondere Gewinnschancen 
erm"ogliche, weil der Jackpot ungew"ohnlich gross sei. Welche Ereignisse
sind in diesem Spiel relevant?

Auf der Euromillions-Website findet man die Erkl"arung, wie das Spiel abl"auft.
Der Spieler kreuzt auf dem Teilnahmeschein (Abbildung~\ref{euromillionsschein})
f"unf Zahlen und zwei Sterne an. Dann erfolgt die Ziehung, Euromillions ermittelt
5 Gewinnzahlen aus dem Bereich 1--50 und 2 Gewinnsterne im Bereich 1--9.
Jetzt werden die "Ubereinstimmungen zwischen dem Tipp des Teilnehmers und den
Gewinnzahlen gez"ahlt. Je besser die "Ubereinstimmung desto gr"osser der Gewinn.

\begin{table}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
Gewinnrang&richtige Zahlen&richtige Sterne&Anteil Gewinnsumme\\
\hline
1&5&2&32.0\%\\
2&5&1&7.4\%\\
3&5&0&2.1\%\\
4&4&2&1.5\%\\
5&4&1&1.0\%\\
6&4&0&0.7\%\\
7&3&2&1.0\%\\
8&3&1&5.1\%\\
9&2&2&4.4\%\\
10&2&0&4.7\%\\
11&1&2&10.1\%\\
12&2&1&24.0\%\\
\hline
\end{tabular}
\end{center}
\caption{Gewinnr"ange bei Euromillions\label{gewinnraenge}}
\end{table}

Die Tabelle \ref{gewinnraenge} zeigt, wie der Gewinn verteilt wird.
Offenbar spielen dabei sogenannte Gewinnr"ange eine besondere Rolle.
Bei jedem Tippzettel wird festgestellt, in welchen Gewinnrang er
geh"ort.

Ausser den Gewinnr"angen k"onnen auch andere Ereignisse eintreten,
die jedoch f"ur die Auszahlung nicht unbedingt von Bedeutung sind,
oder aus denen sich der Gewinn noch nicht ableiten l"asst:
\begin{itemize}
\item {\it Heiris Euromillions Teilnahmeschein f"allt in Gewinnrang 10.} Offenbar
teilt sich Heiri 4.7\% der Gewinnsumme mit den anderen Teilnehmern, die
dasselbe Ergebnis erziehlt haben.
\item {\it Hanna hatte f"unf richtige Zahlen.} Diese Information reicht noch
nicht, um den Gewinn festzulegen. Hannas Teilnahmeschein f"allt in
Gewinnrang 1 oder 2 oder 3.
\item {\it Hermine hatte keinen einzigen Stern richtig.} Hermine k"onnte
etwas gewonnen haben, n"amlich wenn sie 5, 4 oder 2 richtige Zahlen
gehabt hat (R"ange 3, 6 bzw.~10). Oder sie k"onnte mit 3, 1 oder 0
richtigen Zahlen nichts gewonnen haben.
\item {\it Hermann hatte richtige Zahlen und Sterne.} Hermann hatte
als 1, 2, 3, 4 oder 5 richtige Zahlen {\em und}
1 oder 2 richtige
Sterne.
\item {\it Es trifft nicht zu, dass Hilary einen richtigen Stern hat.}
\item {\it Holger hat auf 47 gesetzt.}
Dieses Ereignis nimmt auf die Ziehung "uberhaupt keinen Bezug,
trotzdem beschreibt es einen m"oglichen Ausgang des Experimentes.
\end{itemize}
Wir stellen fest, dass Ereignisse mit {\em und} (beide Ereignisse sind
eingetreten) und {\em oder} (eines der Ereignisse ist
eingetreten) verkn"upft werden k"onnen. Ausserdem k"onnen 
Ereignisse negiert werden.

\subsection{Produkte}
\begin{figure}
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
(1,1)&(1,2)&(1,3)&(1,4)&(1,5)&(1,6)\\
\hline
(2,1)&(2,2)&(2,3)&(2,4)&(2,5)&(2,6)\\
\hline
(3,1)&(3,2)&(3,3)&(3,4)&(3,5)&(3,6)\\
\hline
(4,1)&(4,2)&(4,3)&(4,4)&(4,5)&(4,6)\\
\hline
(5,1)&(5,2)&(5,3)&(5,4)&(5,5)&(5,6)\\
\hline
(6,1)&(6,2)&(6,3)&(6,4)&(6,5)&(6,6)\\
\hline
\end{tabular}
\end{center}
\caption{Elementarereignisse f"ur das W"urfeln mit zwei unterscheidbaren
W"urfeln\label{ereignisse-zwei-wuerfel}}
\end{figure}
Wir stellen uns vor, dass ein roter und ein blauer W"urfel geworfen werden.
Die von den beiden W"urfeln gezeigten Augenzahlen sind verschiedene
Versuchsausg"ange, sozusagen ``rote'' und ``blaue'' Zahlen. Das Resultat
eines Wurfes ist also ein Paar bestehend aus einer ``roten'' und
einer ``blauen'' Augenzahl. Die Menge aller m"oglichen Ausg"ange
ist also 
\[
\Omega = \Omega_{\text{rot}}\times\Omega_{\text{blau}},
\]
das kartesische Produkt der Mengen $\Omega_{\text{rot}}$ und
$\Omega_{\text{blau}}$ (siehe auch Abbildung \ref{ereignisse-zwei-wuerfel}).

In $\Omega$ lassen sich bereits bedeutend spannendere Ereignisse
beschreiben:
\begin{align*}
A_1&=\{\text{mindestens eine ungerade Zahl}\}\\
   &=\{(x,y)\in\Omega\;|\;x \equiv 1\mod 2 \vee y\equiv 1\mod 2\}\\
A_2&=\{\text{beide Augenzahlen sind gerade}\}\\
   &=\{(x,y)\in\Omega\;|\;2|x \wedge 2|y\}\\
X_i&=\{(i,y)\in\Omega\}\\
Y_i&=\{(x,i)\in\Omega\}\\
S_s&=\{(x,y)\in\Omega\;|\; x + y = s\}\\
D_d&=\{(x,y)\in\Omega\;|\; |x - y| = d\}\\
\end{align*}
Und damit lassen sich auch etwas spannendere Rechnungen durchf"uhren. Zum
Beispiel:
\begin{align*}
A_1&=\Omega \setminus A_2 = \bar A_2\\
A_1\cap A_2&=\emptyset\\
A_1&=X_1\cup X_3 \cup X_5\cup Y_1\cup Y_3\cup Y_5\\
X_4\cap Y_3&=\{(4,3)\}\\
X_5\cap S_7&=\{(5,2)\}\\
X_5\cap D_1&=\{(5,4), (5,6)\}\\
\end{align*}
\begin{figure}
\centering
\includegraphics{images/zweiwuerfel-1.pdf}
\caption{Verschiedene Ereignisse in der Ereignisalgebra des Experiments
``Wurf zweier verschiedenfarbiger W"urfel\label{zweiwuerfel}}
\end{figure}

\subsection{Formale Definition}
Damit obige Definition von Ereignissen funktioniert, m"ussen
alle Operationen in der Tabelle~\ref{begriffe-zusammenfassung}
ausf"uhrbar sein.
Die Menge aller Teilmengen von $\Omega$, die Potenzmenge
$P(\Omega)$ erf"ullt diese Bedingung,
ist aber sehr gross und hat sehr wenig n"utzliche Struktur, die
f"ur den Aufbau des Begriffs der Wahrscheinlichkeit im n"achsten
Abschnitt ben"otigt wird.
Insbesondere stellt sich heraus, dass es nicht m"oglich ist,
den Begriff der Wahrscheinlichkeit konsistent zu definieren, wenn
Ereignisse beliebige Teilmengen einer unendlichen Menge $\Omega$
sein d"urfen.

Ein Beispiel f"ur diese Situation sind Messwerte, in diesem
Fall ist $\Omega=\mathbb R$ unendlich.
Es werden aber auch nicht alle Teilmengen von $\mathbb R$ ben"otigt.
Es wird gen"ugen, wenn wir alle Intervalle zur Verf"ugung haben sowie
alle Mengen, die sich daraus durch endlich viele Mengenoperationen
konstruieren lassen.
Statt der Menge $P(\Omega)$ wird also eine kleinere Menge $\cal A$
von Ereignissen verwendet.
Man kann zeigen, dass sich aus der Menge der Intervalle immer 
eine Menge von Ereignissen konstruieren l"asst, in der alle
n"otigen Operationen ausgef"uhrt werden k"onnen, und auf der sich
die sp"ater einzuf"uhrende Wahrscheinlichkeit konsistent definieren
l"asst.

Die Einschr"ankung auf $\cal A$ hat mindestens im Rahmen dieser
Vorlesung keine praktischen Konsequenzen, alle interessierenden
Ereignisse sind von vornherein in $\cal A$, und damit auch alle daraus
abgeleiteten Ereignisse.

Wir nennen eine solche Menge von Ereignissen eine Ereignis-Algebra:

\begin{definition}
\label{def-ereignisalgebra}
Eine {\em Ereignisalgebra} $(\Omega,{\cal A})$ ist
eine Menge $\Omega$ mit einer Menge ${\cal A }\subset{\cal P}(\Omega)$
von Teilmengen von $\Omega$, die folgende Bedingungen erf"ullen:
\begin{enumerate}
\item Vereinigungen von Elementen von ${\cal A}$ sind ebenfalls in ${\cal A}$,
also
\[
A,B\in {\cal A}\Rightarrow A\cup B\in{\cal A}
\]
\item Differenzen von Elementen von ${\cal A}$ sind in ${\cal A}$, also
\[
A,B\in {\cal A}\Rightarrow A\setminus B\in{\cal A}
\]
\item $\Omega\in{\cal A}$, d.h. es gibt das sichere Ereignis.
\end{enumerate}
\end{definition}

Sind nur die Bedingungen 1 und 2 erf"ullt, spricht man auch von einem
Mengen-Ring. Eine Ereignisalgebra heisst manchmal auch ein Mengen-K"orper.

Aus den Axiomen f"ur die Ereignisalgebra lassen sich sofort erst
Schlussfolgerungen ziehen:
\begin{enumerate}
\item Es gibt auch das unm"ogliche Ereignis: $\emptyset = \Omega\setminus\Omega\in{\cal A}$.
\item Das Komplement eines Ereignisses ist ebenfalls ein Ereignis: $\bar A=\Omega\setminus A\in{\cal A}$.
\item Der Durchschnitt zweier Ereignisse ist ebenfalls ein Ereignis: $A\cap B = 
(A\cup B) \setminus ((A\setminus B) \cup (B\setminus A))\in{\cal A}$.
\end{enumerate}

\section{Weitere Beispiele von Ereignisalgebren} \label{section-beispiele}
\subsection{Dominosteine}
Die Menge aller m"oglichen Dominosteine wurde bereits fr"uher untersucht.
Jetzt m"ochten wir darin einzelne Ereignisse auszeichnen. Wir beschreiben
einen einzelnen Dominostein als ein paar $(x,y)$, wobei $x\ge y$ sein soll.
Beispiele von Ereignissen:
\begin{align*}
S_k&=\{ \text{Die Augensumme ist $k$}\}\\
S_5&=\{ (5,0), (4,1), (3,2) \}\\
S_4&=\{ (4,0), (3,1), (2,2) \}\\
R&=\{\text{die Augenzahlen sind positiv haben keinen gemeinsamen Teiler $>1$}\}\\
 &=\{ (6,5), (6,1), (5,4), (5,3), (5,2), (5,1), (4,3), (4,1), (3,2), (3,1), (2,1), (1,1) \}
\\
P&=\{\text{beide Augenzahlen sind Primzahlen}\}\\
 &=\{(5,5), (5,3), (5,2), (3,3), (3,2), (2,2) \}\\
\end{align*}

\subsection{W"urfeln mit zwei W"urfeln}
Bei einem W"urfelspiel wirft man jeweils zwei W"urfel. Zeigen beide W"urfel
die gleiche Zahl, man nennt dies einen {\em Pasch}, darf man genau ein
weiteres Mal w"urfeln.
Die Elementarereignisse sind also entweder einfach Paare, also von
der Form $(x,y)$, mit $x\ne y$, oder ein Pasch gefolgt von irgend einem
W"urfelresultat, wir schreiben dies $(P_k, (x,y))$, also ein $k$-er-Pasch
gefolgt von einem Paar $(x,y)$, wobei diesmal keine Einschr"ankungen f"ur
$x$ und $y$ gelten.
Damit kann man jetzt alle m"oglichen Elementarereignisse auflisten
\begin{align*}
\Omega=\{
&\phantom{(6,6),} (6,5), (6,4), (6,3), (6,2), (6,1)\\
&(5,6), \phantom{(5,5),} (5,4), (5,3), (5,2), (5,1)\\
&(4,6), (4,5), \phantom{(4,4),} (4,3), (4,2), (4,1)\\
&(3,6), (3,5), (3,4), \phantom{(3,3),} (3,2), (3,1)\\
&(2,6), (2,5), (2,4), (2,3), \phantom{(2,2),} (2,1)\\
&(1,6), (1,5), (1,4), (1,3), (1,2), \phantom{(1,1)}
\}
\\
&\cup
\{(P_6,(x,y))\}
\cup
\{(P_5,(x,y))\}
\cup
\{(P_4,(x,y))\}
\\
&\cup
\{(P_3,(x,y))\}
\cup
\{(P_2,(x,y))\}
\cup
\{(P_1,(x,y))\}
\end{align*}
Man sieht daraus zum Beispiel, dass es $30 + 6\cdot 36=246$
Elementarereignisse gibt. Darin enthalten sind die Ereignisse
\begin{align*}
P&=\{\text{Pasch im ersten Wurf}\}\\
&=
\{(P_6,(x,y))\}
\cup
\{(P_5,(x,y))\}
\cup
\{(P_4,(x,y))\}
\\
&\qquad \cup
\{(P_3,(x,y))\}
\cup
\{(P_2,(x,y))\}
\cup
\{(P_1,(x,y))\}
\\
\tilde P_k&=\{\text{$k$-er Pasch im ersten Wurf}\}\\
   &=\{(P_k,(x,y))\}
\\
Q&=\{\text{totale Augensumme $\ge 10$}\}\\
&=\{\phantom{(6,6),} (6,5), (6,4), \\
&\phantom{\;=\{}(5,6), \phantom{(5,5),} \\
&\phantom{\;=\{}(4,6)
\}
\\
&\qquad\cup
\{(P_6,(x,y))\}
\cup
\{(P_5,(x,y))\}
\cup
\{(P_4,(x,y))\,|\, x+y \ge 2\}
\\
&\qquad\cup
\{(P_3,(x,y))\,|\, x+y \ge 4\}
\cup
\{(P_2,(x,y))\,|\, x+y \ge 6\}
\\
&\qquad
\cup
\{(P_1,(x,y))\,|\, x+y \ge 8\}
\end{align*}

\subsection{AIDS-Test}
Wir mathematisieren das Beispiel des AIDS-Tests.
Die fr"uhere Diskussion f"uhrt uns vor Augen,
dass wir hier mit zwei verschiedenen Ereignissen zu tun haben. 
Das Experiment besteht offenbar darin, dass wir jemanden untersuchen,
die Menge der Elementarereignisse ist also die Menge aller betrachteten
Personen.
Darin unterscheiden wir:
\begin{align*}
H&=\{\text{Person hat HIV}\}\\
T&=\{\text{Person hat positiven AIDS-Test}\}
\end{align*}
Es ist klar, dass $H\ne T$. Es gibt Personen, die zwar HIV haben, bei
denen der Test dies aber noch nicht zeigen kann, $H\setminus T\ne \emptyset$.
Andererseits gibt es falsche positive Testresultate,
$T\setminus H\ne\emptyset$. 

\subsection{Messwertalgebra}
\begin{table}
\begin{center}
\begin{tabular}{|cc|cc|}
\hline
1&0.990
&11&0.990\\
2&0.989
&12&0.989\\
3&0.991
&13&0.990\\
4&0.991
&14&0.991\\
5&0.991
&15&0.989\\
6&0.989
&16&0.990\\
7&0.990
&17&0.989\\
8&0.989
&18&0.990\\
9&0.992
&19&0.990\\
10&0.992
&20&0.991\\
\hline
\end{tabular}
\end{center}
\caption{Werte von Stichprobe von 20 1k$\Omega$-Widerst"anden\label{widerstandswerte}}
\end{table}
Bei einer Messung wird ein Messwert ermittelt, dieser kann jedoch
nur mit einer begrenzten Genauigkeit festgehalten werden.
Die Elementarereignisse sind zwar immer noch alle m"oglichen rellen
Zahlen $\mathbb R$, aber sinnvolle Ereignisse sind nur bestimmte Teilmengen
$A\subset\mathbb R$. Wir wollen bestimmen, welche Teilmengen das sind.

Zun"achst f"uhren wir dies an einem Beispiel durch.
Bei einer am 1.~November 2006
zuf"allig bei Pusterla in Z"urich gekauften Stichprobe von 20 1k$\Omega$
Widerst"anden ergaben sich beim Nachmessen die Widerstandswerte in 
Tabelle \ref{widerstandswerte}. Offensichtlich streuen die Messwerte
zwischen 0.989 und 0.992. Genauere Informationen kann das Messger"at nicht
anzeigen. Wir k"onnen aus den Daten also eigentlich nur folgendes schliessen:
der Widerstand mit der Nummer eins hat einen Wert $0.990\le R_1<0.991$.
Der Widerstandswert $R_1$ ist ein Versuchsergebnis, also ein Elementarereignis,
liegt aber in der Menge
\[
A=[0.990,0.991)\subset \mathbb{R}=\Omega.
\]
Ausserdem werden durch die weiteren Messungen auch noch folgende
Ereignisse realisiert:
\begin{center}
\begin{tabular}{|c|c|}
\hline
Ereignis&H"aufigkeit\\
\hline
$[0.989,0.990)$&6\\
$[0.990,0.991)$&7\\
$[0.991,0.992)$&5\\
$[0.992,0.993)$&2\\
\hline
\end{tabular}
\end{center}
Diese speziellen Ereignisse beinhalten offensichtlich alle Information,
die wir "uber die Widerst"ande haben k"onnen.
Bei den 20 Versuchen treten aber auch noch andere Ereignisse ein,
zum Beispiel
\begin{center}
\begin{tabular}{|c|c|}
\hline
Ereignis&H"aufigkeit\\
\hline
$\{R\ge 0.990\}$&14\\
``5\% Toleranz'' = $\{0.95\le R\le1.05\}$&20\\
``1\% Toleranz'' = $\{0.99\le R\le 1.01\}$&14\\
\hline
\end{tabular}
\end{center}

Etwas formaler: Eine Genauigkeitsangabe bei einem Messwert definiert
ein Intervall, in dem sich ein Messwert befinden muss. Wir
fordern also, dass $\cal A$ alle Intervalle der Form $[a,b]\subset\mathbb R$
enthalten muss.
Aber auch die Aussage ``der Messwert ist kleiner als $a$''
muss einem Ereignis in $\cal A$ entsprechen, also m"ussen auch Intervalle,
die sich ins unendliche erstrecken in $\cal A$ sein:
\begin{align*}{}
(-\infty,r]&=\{x\in\mathbb R\;|\;x \le r\} \in \cal A\\
% Hack: \; brauchts, damit eqnarray nicht meint [ leite ein Argument ein
\;[r,\infty)&=\{x\in\mathbb R\;|\;x \ge r\} \in \cal A
\end{align*}

Da wir Komplemente bilden k"onnen, m"ussen auch die offenen Intervalle
\begin{align*}
\overline{[a,\infty)}&=\mathbb R\setminus [a,\infty)=(-\infty,a)\in\cal A\\
\overline{(-\infty,b]}&=\mathbb R\setminus (-\infty,b]= (b,\infty)\in\cal A
\end{align*}
Ereignisse sein. Ein beliebiges offenes Intervall l"asst sich
als Durchschnitt zweier solcher Intervalle ausdr"ucken:
\[
(a,b)=(-\infty, b)\cap(a,\infty).
\]
Durch Bildung von geeigneten Durchschnitten lassen sich also alle
Intervalle bilden. Ausserdem m"ussen alle Teilmengen von $\mathbb R$
zu $\cal A$ hinzugenommen werden, die sich durch Bildung von Komplementen,
Durchschnitten und Vereinigungen bilden lassen. Offensichtlich ist $\cal A$
in diesem Falle sehr kompliziert.

\section{Wahrscheinlichkeit} \label{section-wahrscheinlichkeit}
In der Einleitung haben wir das Ereignis diskutiert, dass die Schweizer
Nati ein bestimmtes Spiel an Fussball WM gewinnt.
Wir sind zum Schluss
gekommen dass wir nicht wissen k"onnen, was bei der konkreten
Durchf"uhrung des Experimentes passieren wird.
Falls der Gegner
stark ist, zum Beispiel Deutschland, dann wird ein Sieg wohl auch
dann kaum je eintreten, wenn man das Spiel viele Male wiederholt.
Das wenigstens verbinden wir mit einem unwahrscheinlichen Ereignis.
Trotzdem kann das Ereignis eintreten.

\subsection{Verschiedene Wahrscheinlichkeitsbegriffe}
Die Wahrscheinlichkeit soll ein Mass daf"ur sein, dass Ereignis
eintritt.
Es gibt verschiedene Ans"atze, wie wir zu einem solchen Mass kommen
k"onnten:
\begin{itemize}
\item 
Je h"aufiger ein Ereignis eintritt, desto gr"osser sollte die
Wahrscheinlichkeit sein. 
Dies setzt voraus, dass das Experiment im Prinzip beliebig oft wiederholbar 
ist.
Man nennt dies den {\em frequentistischen} Ansatz.
\item
Die Wahrscheinlichkeit ist ein Mass f"ur die pers"onliche
"Uberzeugung, dass ein Ereignis eintreten wird.
Im Unterschied zum frequentistischen Ansatz sollte man bei diesem
Ansatz einem Ereignis auch dann eine Wahrscheinlichkeit geben k"onnen,
wenn sich ein Experiment nicht wirklich wiederholen l"asst.
Dies ist der Bayessche Ansatz.
\item
Wir k"onnten eine Reihe von Axiomen postulieren, nach denen sich
die Wahrscheinlichkeit zu verhalten hat, und dann zu untersuchen,
ob ein solches Objekt tats"achlich existiert.
\end{itemize}
In allen F"allen ergibt sich eine Reihe von Gesetzm"assigkeiten
oder Formeln, die die jeweiligen Wahrscheinlichkeitsbegriffe 
erf"ullen m"ussen.
Soll die Wahrscheinlichkeit eine objektive Gr"osse sein, dann
muss f"ur wiederholbare Experimente die f"ur den Bayesschen
Ansatz n"otige pers"onliche "Uberzeugung direkt mit der H"aufigkeit
des Eintretens zusammenh"angen.
Der frequentistische und der Bayessche Ansatz werden also in diesem
Fall "ubereinstimmen.
Die Axiome im axiomatischen Ansatz sind nat"urlich genau die
Rechenregeln, die man sowohl im frequentistischen Ansatz wie
auch im Bayesschen Ansatz von der Wahrscheinlichkeit erwartet.
Man darf daher davon ausgehen, dass die drei Ans"atze die gleichen numerischen
Resultate liefern, sie unterscheiden sich h"ochstens in der Interpretation
der Resultate.
Wir werden daher im Folgenden vor allem den am leichtesten zu
verstehenden frequentistischen Ansatz verfolgen.

\subsection{Wahrscheinlichkeit als relative H"aufigkeit}
Wir wollen nun einen Begriff der Wahrscheinlichkeit einf"uhren, der
einer intuitiven Vorstellung zu diesem Wort m"oglichst nahe kommt.
Wenn ``sehr
wahrscheinlich'' heissen soll ``in der Mehrzahl der F"alle'', dann
bedeutet das offensichtlich, dass man eine gr"ossere Zahl von
Experimenten durchf"uhren soll, und dann die F"alle z"ahlen soll,
in denen das Ereignis tats"achlich eingetreten ist. Deren Anteil
an der Gesamtzahl heisst {\em relative H"aufigkeit} und ist eine erste,
etwas pr"azisere Fassung des Begriffs der Wahrscheinlichkeit. 

Grundlegend f"ur die Wahrscheinlichkeitsrechnung ist die aus der
\index{Wahrscheinlichkeit!als relative H\"aufigkeit}
Erfahrung mit einer grossen Zahl von Versuchen gewonnene Zuversicht,
dass die relative H"aufigkeit mit wachsender Anzahl Versuche gegen
eine Gr"osse $P(A)$ strebt. Man verwendet diese Annahme daher als
Definition. Wiederholt
man ein Experiment $N$ Male, und tritt dabei das Ereignis $A$
genau $n$ mal ein, dann erwartete man, dass der Quotient $\frac{n}{N}$
eine gute N"aherung f"ur $P(A)$ ist. Je "ofter man das Experiment
wiederholt, desto n"aher sollte der Quotient der Gr"osse $P(A)$
kommen, also
\[
P(A) := \lim_{N\to\infty}\frac{n}{N}.
\]

Leider ist es nur selten praktikabel, das Experiment tats"achlich
sehr h"aufig zu wiederholen.  Bei der Pr"ufung neuer Medikamente
zum Beispiel hindern moralische Bedenken daran, eine grosse
Zahl von Experimenten mit Menschen durchzuf"uhren. Bei der
Ausbruchswahrscheinlichkeit eines Vulkans oder der
Einschlagswahrscheinlichkeit eines Asteroiden auf der Erde hat man
ganz einfach keine Kontrolle "uber das Experiment.

Das Ziel der Wahrscheinlichkeitstheorie ist daher, 
die Abbildung $P\colon {\cal A}\to\mathbb{R}$
abstrakt zu definieren, und geeignete Axiome zu postulieren, die
der eben skizzierten intuitiven Vorstellung der Wahrscheinlichkeit
einen strengen Sinn geben. Damit wird die Funktion $P$ in vielen
F"allen berechenbar, meist nat"urlich unter zus"atzlichen Annahmen.
Die grundlegenden Eigenschaften sind in den folgenden, f"ur
relative H"aufigkeiten unmittelbar einleuchtenden Axiomen
% XXX
von Kolmogorov\footnote{Andrei Nikolaiewitsch Kolmogorov, 1903-1987}
festgehalten.
\index{Kolmogorov, Andrei Nikolaiewitsch}

\subsubsection{Axiome  eines Wahrscheinlichkeitsraumes}
\index{Axiome eines Wahrscheinlichkeitsraumes}

\begin{description}
\item[Wertebereich.]F"ur jedes beliebige Ereignis $A\subset \Omega$
gilt
\begin{equation}
0\le P(A)\le 1.
\label{p-wertebereich}
\end{equation}
\item[Sicheres Ereignis.] F"ur das sichere Ereignis gilt
\begin{equation}
P(\Omega) = 1.
\label{p-sicheresereignis}
\end{equation}
\item[Vereinigung.] Sind die Ereignisse $A_1,A_2,\dots$ paarweise
disjunkt, also $A_i\cap A_j=\emptyset$ f"ur $i\ne j$, dann gilt
\begin{equation}
P(A_1\cup A_2\cup \dots) = P(A_1) + P(A_2) + \dots
\label{p-summenformel}
\end{equation}
\end{description}

Die Forderung "uber die Vereinigung kann nat"urlich nur dann "uberhaupt
formuliert werden, wenn die Vereinigung auch wirklich ein Ereignis ist, also in
$\cal A$ ist.
Bisher wissen wir nur, dass endliche
Vereinigungen von Ereignissen gebildet werden k"onnen, jetzt m"ussen
wir fordern, dass
auch unendliche Vereinigungen von Ereignissen wieder Ereignisse sind.
D.h. wir setzen im Folgenden voraus, dass in einer
Ereignisalgebra in Erweiterung des ersten Axioms auch gilt:

\begin{definition}
$\cal A$ heisst 
$\sigma$-Algebra, wenn 
abz"ahlbare Vereinigungen von Elementen von $\cal A$ ebenfalls
in $\cal A$ sind, d.~h.~falls $A_i\in{\cal A}$ f"ur $i\in\mathbb{N}$, dann ist
\[
A_1\cup A_2\cup\dots=\bigcup_{i=0}^{\infty}A_i \in{\cal A}.
\]
\end{definition}

In allen praktischen F"allen ist diese technische Bedingung automatisch
erf"ullt, oder man kann erzwingen, dass sie erf"ullt ist.
F"ur die Praxis ist dies also keine Einschr"ankung, man kann immer davon
ausgehen, dass die Vereinigungsformel~(\ref{p-summenformel}) ``funktioniert''.

\subsection{Beispiel: W"urfeln}
Beim W"urfeln mit einem W"urfel erwartet man, dass jeder m"ogliche
Ausgang etwa gleich h"aufig sein wird. Bei einer grossen Zahl von
Versuchen wird man also feststellen, dass die relative H"aufigkeit
des Ereignisses, dass eine $4$ gew"urfelt wird, gegen $\frac16$
konvergieren wird. Die zus"atzliche Annahme steckt in diesem Fall
darin, dass man alle Ausg"ange als gleich wahrscheinlich annimmt.

\begin{table}
\begin{center}
\begin{tabular}{|l|r|r|r|r|r|r|r|r|}
\hline
Anzahl&6&96&996&9996&99996&999996&9999996&99999996\\
\hline
0& 0& 17& 168& 1642& 16746& 166434& 1665609& 16662248\\
1& 1& 17& 160& 1692& 16747& 166584& 1666841& 16669513\\
2& 1& 11& 178& 1680& 16491& 167031& 1667271& 16663991\\
3& 0& 16& 158& 1660& 16672& 165940& 1665310& 16659406\\
4& 3& 13& 159& 1634& 16756& 167026& 1668244& 16672749\\
5& 1& 22& 173& 1688& 16584& 166981& 1666721& 16672089\\
\hline
Maximum& 3& 22& 178& 1692& 16756& 167031& 1668244& 16672749\\
Minimum& 0& 11& 158& 1634& 16491& 165940& 1665310& 16659406\\
$\Delta$& 3& 11& 20& 58& 265& 1091& 2934& 13343\\
\hline
\end{tabular}
\end{center}
\caption{Computer-Simulation eines fairen W"urfels\label{wuerfel-simulation}}
\end{table}

Die tats"achliche Durchf"uhrung von ``gen"ugend'' vielen Experimenten
kann hingegen schwierig sein. Eine Computer-Simulation des
W"urfel-Experiments zeigt zum Beispiel die Resultate in Tabelle
\ref{wuerfel-simulation}. Offensichtlich ist selbst mit $10^8$
W"urfen die Wahrscheinlichkeit erst auf drei Stellen nach dem Komma
genau.

\subsection{Folgerungen aus den Axiomen}
\begin{satz}Es gilt
\begin{enumerate}
\item Die Wahrscheinlichkeit des unm"oglichen Ereignisses ist
\begin{equation}
P(\emptyset) = 0.
\label{p-emptyset}
\end{equation}
\item Die Wahrscheinlichkeit des komplement"aren Ereignisses
ist
\begin{equation}
P(\bar A) = P(\Omega\setminus A) = 1 -P(A).
\label{p-negation}
\end{equation}
\item Die Wahrscheinlichkeit der Differenz der Ereignisse $A$ und $B$
ist
\begin{equation}
P(A\setminus B) = P(A) - P(A\cap B)
\label{p-complement} % changed
\end{equation}
\item Die Wahrscheinlichkeit der Vereinigung zweier beliebiger Ereignisse
ist
\begin{equation}
P(A\cup B) = P(A) + P(B) - P(A\cap B)
\label{p-union}
\end{equation}
(Ein-/Ausschaltformel).
\index{Ein-/Ausschaltformel}
\end{enumerate}
\end{satz}

\begin{proof}[Beweis]
Wegen $\Omega = \Omega \cup\emptyset$ und
$\Omega\cap\emptyset = \emptyset$ folgt aus dem Axiom
"uber die Vereinigung  (\ref{p-summenformel})
\[
P(\Omega) = P(\Omega \cup \emptyset) = P(\Omega) + P(\emptyset)
\]
Indem man auf beiden Seiten der Gleichung $P(\Omega)$ subtrahiert,
folgt $0 = P(\emptyset)$.

F"ur das komplement"are Ereignis gilt $A\cap\bar A=\emptyset$ und
$A\cup\bar A=\Omega$. Aus der Summenformel (\ref{p-summenformel}) folgt
\[
1 = P(\Omega) = P(A\cup\bar A) = P(A) + P(\bar A)
\]
oder
\[
P(\bar A) = 1 - P(A).
\]

$A$ ist die disjunkte Vereinigung $A=(A\setminus B) \cup (A\cap B)$,
also gilt
\[
P(A)=P(A\setminus B) + P(A\cap B),
\]
oder, nach $P(A\setminus B)$ aufgel"ost
\[
P(A\setminus B) = P(A) - P(A\cap B).
\]

Nach der de Morganschen Regel l"asst sich die Vereinigungsmenge
als disjunkte Vereinigung schreiben:
\[
A\cup B =  (A\setminus B) \cup (A\cap B) \cup (B\setminus A)
\]
Also gilt
\begin{align*}
P(A\cup B)&=P(A\setminus B) + P(A\cap B) + P(B\setminus A)\\
&=P(A) - P(A\cap B) + P(A\cap B) + P(B) - P(A\cap B)\\
&=P(A) + P(B) - P(A\cap B).
\end{align*}
\end{proof}
Damit stehen uns Rechenregeln zur Verf"ugung, mit deren Hilfe wir
die Wahrscheinlichkeit beliebiger Ereignisse auf der Basis einiger
weniger Annahmen berechnen k"onnen.

\subsection{Wahrscheinlichkeit als Mass}
Die Wahrscheinlichkeitsfunktion $P$ hat genau die Eigenschaften,
die man von einer Fl"achenmessung erwartet.
Die Gesamtfl"ache disjunkter Fl"achenst"ucke berechnet man,
indem man den Fl"acheninhalt der einzelnen Fl"achenst"ucke summiert.
Das leere Fl"achenst"uck hat keinen Inhalt.
Einzig die zus"atzliche Forderung $P(\Omega)=1$, welche
sicherstellt, dass die Wahrscheinlichkeit nicht gross werden kann,
hat keine Entsprechung.

Demzufolge k"onnen Ereignisse oft auch als Fl"achen in einem Diagramm
visualisiert werden,
die umso gr"osser sind, je gr"osser die Wahrscheinlichkeit des Ereignisses
ist. Bei einem Dart-Spiel liegt es nahe, dass die Wahrscheinlichkeit, ein
bestimmtes Feld zu treffen, umso gr"osser ist, je gr"osser der Fl"achen-Anteil
dieses Feldes an der ganzen Scheibe ist. Nat"urlich trifft dies nur bei einem
sehr schlechten Dart-Spieler zu, dessen Pfeile gleichm"assig verteilt auf
die Scheibe treffen.

Diese
"Uberlegung kann jedoch dazu verwendet werden, die Wahrscheinlichkeiten
eines Meteoriteneinschlages in der Schweiz und im F"urstentum Liechtenstein
miteinander zu vergleichen. Wir erwarten, dass die Wahrscheinlichkeit
proportional zur Fl"ache sein wird, also
\[
\frac{P(\text{CH})}{P(\text{FL})}=
\frac{41285\text{km$\mathstrut^2$}}{160\text{km$\mathstrut^2$}}
=258.03,
\]
die Wahrscheinlichkeit f"ur einen Meteoriteneinschlag im L"andle ist also
"uber 258mal kleiner.

Umgekehrt k"onnte man die Idee zu einer Fl"achenberechnungs- oder
Integra\-tions\-methode ausbauen. Um den Fl"acheninhalt einer unregelm"assigen
Teilmenge
eines Rechteckes in der Ebene zu bestimmen, simuliert man mit dem
Computer gleichm"assig verteilte ``Sch"usse'' auf diese ``Zielscheibe''.
Der Anteil der Treffer in der Teilmenge ergibt ein Mass f"ur dessen
Fl"ache. Leider ist das Verfahren in dieser Form praktisch nicht
durchf"uhrbar, weil viel zu viele ``Sch"usse'' notwendig sind, um
eine gen"ugende Genauigkeit zu erreichen. Es kann aber durchaus
zu einem praktikablen Verfahren verfeinert werden (Monte Carlo Methoden).

Wegen
der Analogie zu einer Fl"achenmessung heisst eine
Wahrscheinlichkeitsfunktion $P$ oft auch ein {\em Wahrscheinlichkeitsmass}. Das
Tripel $(\Omega,{\cal A}, P)$ heisst ein {\em Wahrscheinlichkeitsraum}.

\section{Laplace-Experimente} \label{section-laplace-ereignisse}
Bisher sind wir nicht in der Lage, die Wahrscheinlichkeit eines Ereignisses
zu berechnen, wir k"onnen nur mit Hilfe der Axiome aus bereits bekannten
Wahrscheinlichkeiten neue Wahrscheinlichkeiten berechnen.
F"ur die Berechnung der Wahrscheinlichkeiten ist zus"atzliche
Information n"otig.

Bei Experimenten mit endlich vielen Ausg"angen ist es manchmal gerechtfertigt
anzunehmen, dass alle Versuchsausg"ange gleich h"aufig und damit gleich
wahrscheinlich sind.
Von einem guten W"urfel erwarten wir, dass er alle Seiten gleich h"aufig
zeigt, eine symmetrische M"unze sollte Kopf und Zahl etwa gleich h"aufig
zeigen.
Unter dieser Annahme k"onnen wir die Wahrscheinlichkeit berechnen:

\begin{definition}
Ein Experiment mit $n=|\Omega|$ Ausg"angen heisst ein {\em Laplace-Experiment},
wenn jeder Versuchsausgang gleich wahrscheinlich mit Wahrscheinlichkeit
\[
P(\{\omega\})=\frac1n,\qquad\omega\in\Omega
\]
ist.
\end{definition}

Da Laplace-Experimente nur endliche viele Ausg"ange haben, kann man aus
den Axiomen auch jede andere Wahrscheinlichkeit berechnen:

\begin{satz}
Bei einem Laplace-Experiment tritt das Ereignis $A\subset\Omega$ mit
Wahrscheinlichkeit
\[
P(A)=\frac{|A|}{|\Omega|}
\]
ein.
\end{satz}
Damit ist die Berechnung der Wahrscheinlichkeit auf das Z"ahlen der 
Versuchsausg"ange in $A$ reduziert, also auf eine Kombinatorik-Aufgabe.

\subsection{M"unze werfen}
\index{Munze@{M\"unze, faire}}
Wirft man eine M"unze, kann sie nur auf einer von zwei Seiten landen,
die Elementarereignisse sind also $\Omega = \{\text{Kopf}, \text{Zahl}\}$.
Die mathematisch idealisierte M"unze ist so d"unn, dass sie nicht auf
der Kante stehen kann. Nach allgemeiner Erfahrung funktioniert f"ur
solche M"unzen der Ansatz von Laplace, d.h. $P(\text{Kopf}) = \frac12$
und $P(\text{Zahl})=\frac12$.

Selbstverst"andlich gibt es auch M"unzen, f"ur die die Laplace-Annahme
nicht funktioniert, gebogene M"unzen fallen zum Beispiel bevorzugt auf die
nach aussen gew"olbte Fl"ache.

\subsection{W"urfeln}
\index{Wurfel@{W\"urfel, fairer}}
W"urfel haben sechs Seiten, die gem"ass der Annahme eines Laplace-Experiments
mit gleicher
Wahrscheinlichkeit obenliegen werden, die Wahrscheinlichkeit jedes
Resultates ist also gleich $P(i) = \frac16, i\in\{1,2,3,4,5,6\}$.
Wird eine Seite des W"urfels beschwert, f"allt er bevorzugt auf diese
Seite, und die Wahrscheinlichkeiten sind nicht mehr gleich.

\begin{figure}
\begin{center}
\includegraphics[width=0.8\hsize]{graphics/Wuerfel5}
\end{center}
\caption{Verschiedene Spielw"urfel\label{bild-spielwuerfel}}
\end{figure}
Man kann auch aus anderen geometrischen K"orpern ``W"urfel'' bauen, die
eine gr"ossere Zahl von Ausg"angen erm"oglichen. Ein Dodekaeder hat
zw"olf Seiten, ein Ikosaeder sogar deren 20, aber auch andere Formen
sind realisierbar, siehe Abbildung~\ref{bild-spielwuerfel}. Der Einfachheit
halber gehen wir im Folgenden immer von sechsseitigen W"urfeln aus.

Das Werfen eines solchen W"urfels erzeugt die folgenden Elementarereignisse
oder Versuchsergebnisse:
\[
\Omega=\{1,2,3,4,5,6\}.
\]
Nach dem Laplace'schen Ansatz wird jedem Elementarereignis die
Wahrscheinlichkeit $\frac16$ zugeschrieben. Damit lassen sich
Wahrscheinlichkeiten berechnen:
\begin{align*}
P(\text{``gerade Zahl''})=P(\{2,4,6\})&=\frac36=0.5\\
P(\text{``durch 3 teilbar''})=P(\{3,6\})&=\frac26=0.333\\
P(< 7)=P(\Omega)&=\frac66=1
\end{align*}

\subsection{Zwei W"urfel}
In verschiedenen Spielen wird mit zwei W"urfeln gespielt, wobei nur
deren Augensumme interessiert. Die Ereignisalgebra dazu wurde bereits
fr"uher vorgestellt, die Elementarereignisse sind Paare $(i,j)$ aus
den Augenzahlen der beiden W"urfel. Die Menge der Elementarereignisse
ist also
% hier brauchen wir wirklich ein eqnarray, wegen dem Spacing
\begin{eqnarray*}
\Omega=&\{&\\
&&(1,1),(1,2),(1,3),(1,4),(1,5),(1,6),\\
&&(2,1),(2,2),(2,3),(2,4),(2,5),(2,6),\\
&&(3,1),(3,2),(3,3),(3,4),(3,5),(3,6),\\
&&(4,1),(4,2),(4,3),(4,4),(4,5),(4,6),\\
&&(5,1),(5,2),(5,3),(5,4),(5,5),(5,6),\\
&&(6,1),(6,2),(6,3),(6,4),(6,5),(6,6),\\
&\},&
\end{eqnarray*}
und $|\Omega|=36$. Wenn nur die Augensumme interessiert, dann will
man offensichtlich die Ereignisse
\begin{align*}
A_2&=\{\Sigma=2\}=\{(1,1)\}\\
A_3&=\{\Sigma=3\}=\{(1,2),(2,1)\}\\
A_4&=\{\Sigma=4\}=\{(1,3),(2,2),(3,1)\}\\
&\vdots\\
A_{12}&=\{\Sigma=12\}=\{(6,6)\}
\end{align*}
untersuchen.
Diese Ereignisse sind einfach auszuz"ahlen, und damit kann man auch
die Wahrscheinlichkeiten bestimmen:
\begin{align*}
P(A_2)=P(A_{12})&=\frac{1}{36},\\
P(A_3)=P(A_{11})&=\frac{2}{36},\\
P(A_4)=P(A_{11})&=\frac{3}{36},\\
P(A_5)=P(A_9)&=\frac{4}{36},\\
P(A_6)=P(A_8)&=\frac{5}{36},\\
P(A_7)&=\frac{7}{36}.
\end{align*}

\subsection{Geburtstagsproblem}
Wie gross ist die Wahrscheinlichkeit, dass unter $n$ Personen zwei
am gleichen Tag Geburtstag haben? Hierbei nimmt man an, dass
jeder Tag im Jahr etwa gleich h"aufig als Geburtstag
vorkommt\footnote{Dies ist
jedoch nicht ganz richtig, wie Geb"arabteilungen in Spit"alern
best"atigen k"onnen. Auch haben gr"ossere Stromausf"alle h"aufig
einen Geburtenzuwachs ungef"ahr neun Monate sp"ater zur Folge.}.
Ein Elementarereignis muss also jeder der $n$ Personen ein
Geburtsdatum aus den $366$ m"oglichen zuweisen. Dies kann man so
formulieren:
\[
\omega=(d_1, d_2, d_3,\dots,d_n)
\]
Dabei ist $d_1$ das Geburtsdatum der ersten Person, $d_2$ das
Geburstdatum der zweiten Person, etc. Der Einfachheit halber kann
man f"ur die $d_i$ einfach Zahlen zwischen 1 und 366 nehmen.

$\Omega$ besteht also aus allen m"oglichen Auswahlen von Geburtstagen
f"ur die $n$ Personen:
% hier brauchen wir wirklich ein eqnarray, wegen dem Spacing
\begin{eqnarray*}
\Omega=&\{&\\
&&(1,1,1,\dots,1),\\
&&(2,1,1,\dots,1),\\
&&(3,1,1,\dots,1),\\
&&\dots\\
&&(365,1,1,\dots,1),\\
&&(366,1,1,\dots,1),\\
&&(1,2,1,\dots,1),\\
&&(2,2,1,\dots,1),\\
&&\dots\\
&&(366,366,366,\dots,366)\\
&\}&
\end{eqnarray*}
Man kann ablesen, dass $|\Omega|=366^n$ ist.

Gefragt ist nun das Ereignis
``zwei Personen haben am gleichen Tag Geburtstag''.
Selbstverst"andlich d"urfen dabei auch alle am gleichen Tag
Geburstag haben, oder es darf zwei Paare geben, die jeweils
"ubereinstimmende Geburtstage haben. Es darf einfach nicht
sein, dass alle Geburtstage verschieden sind. Also ist eigentlich
gemeint:
\begin{align*}
A&=\{\text{``zwei haben am gleichen Tag Geburstag''}\}\\
&=\{\text{``nicht alle Geburtstage sind verschieden''}\}\\
&=\overline{\{\text{``alle Geburstage sind verschieden''}\}}.
\end{align*}
In dieser letzten Form ist die Wahrscheinlichkeit einfacher zu
berechnen. Es gilt ja:
\begin{align*}
P(A)&=P(\{\text{``zwei haben am gleichen Tag Geburstag''}\})\\
&=1-P(\{\text{``alle Geburstage sind verschieden''}\})
\end{align*}
Die Anzahl der Geburtstagsverteilungen, bei denen alle Geburtstage
verschieden sind, ist einfach zu ermitteln: F"ur die erste Person
kann man $366$ Geburtstage ausw"ahlen, f"ur die zweite $365$, die
dritte $364$ etc. Insgesamt hat man
\[
366\cdot365\cdot364\dots(366-n+1)
\]
M"oglichkeiten. Also ist die Wahrscheinlichkeit, dass unter $n$
Personen zwei am gleichen Tag Geburtstag haben:
\[
P(A)
=
1-\frac{366\cdot365\cdot364\dots(366-n+1)}{366^n}
=
1-\frac{366}{366}\cdot
\frac{365}{366}\cdot
\frac{364}{366}
\cdots
\frac{366-n+1}{366}
.
\]
Man kann diese Wahrscheinlichkeiten mit einem kleinen Programm
ausrechnen, und findet die Resultate in
Tabelle~\ref{geburtstagswahrscheinlichkeit}.
\begin{table}
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|}
\hline
$n$&$P$&$n$&$P$&$n$&$P$&$n$&$P$\\
\hline
1&0.0000
&11&0.1408
&21&0.4428
&31&0.7295\\
2&0.0027
&12&0.1666
&22&0.4748
&32&0.7524\\
3&0.0082
&13&0.1939
&23&0.5063
&33&0.7740\\
4&0.0163
&14&0.2226
&24&0.5373
&34&0.7944\\
5&0.0271
&15&0.2523
&25&0.5677
&35&0.8135\\
6&0.0404
&16&0.2829
&26&0.5972
&36&0.8313\\
7&0.0561
&17&0.3143
&27&0.6258
&37&0.8479\\
8&0.0741
&18&0.3461
&28&0.6534
&38&0.8633\\
9&0.0944
&19&0.3783
&29&0.6799
&39&0.8775\\
10&0.1166
&20&0.4106
&30&0.7053
&40&0.8905\\
\hline
\end{tabular}
\end{center}
\caption{Wahrscheinlichkeit daf"ur, dass unter $n$ Personen zwei
am gleichen Tag Geburtstag haben.\label{geburtstagswahrscheinlichkeit}}
\end{table}
Ab $n=23$ kann man also wetten, dass zwei Personen am gleichen Tag
Geburtstag haben.

\section{Bedingte Wahrscheinlichkeit}
\index{Wahrscheinlichkeit!bedingte}
\begin{figure}
\begin{center}
\includegraphics{images/algebra-1}
\end{center}
\caption{Ereignisalgebra mit ausgezeichneten Ereignis $B$\label{bedingt1}}
\end{figure}
\begin{figure}
\begin{center}
\includegraphics{images/algebra-2}
\end{center}
\caption{Ereignisalgebra wie in Abbildung \ref{bedingt1} eingeschr"ankt auf das Ereignis $B$\label{bedingt2}}
\end{figure}
In der Praxis fragt man oft nach der Verkettung von Umst"anden: hat ein
Patient bessere Heilungschancen wenn er dieses neue Medikament nimmt?
Man k"onnte das auch so formulieren: ist das Ereignis
``Patient wird gesund, unter der Voraussetzung, dass er das Medikament nimmt''
wahrscheinlicher als das Ereignis ``Patient wird gesund''? Wir m"ussen
also aus der Ereignis\-algebra der Patienten eine neue bilden, die nur
aus den Patienten besteht, welche das Medikament genommen haben.

Wenn $(\Omega, {\cal A})$ eine Ereignisalgebra ist, und 
$B\in{\cal A}$ ein Ereignis (Abbildung~\ref{bedingt1}),
dann kann man eine neue Ereignisalgebra
$(\Omega_{|B}, {\cal A}_{|B})$ wie folgt bilden (Abbildung~\ref{bedingt2}).
Die Menge der Elementarereignisse ist
\[
\Omega_{|B}=B
\]
und die Menge der Ereignisse
\[
{\cal A}_{|B}=\{A\cap B\;|\; A\in{\cal A}\}.
\]
Es w"are noch nachzupr"ufen, dass diese Menge alle Axiome einer
Ereignisalgebra erf"ullt sind\footnote{Da diese technischen Feinheiten 
f"ur die Zwecke dieses Skripts von untergeordneter Bedeutung sind, verzichten
wir auf die explizite Verifikation.}.
Diese Konstruktion macht $B$ zum sicheren Ereignis, d.h. in der ``Welt''
$(\Omega_{|B},{\cal A}_{|B})$ trifft $B$ immer ein (Abbildung~\ref{bedingt2}).
In $(\Omega_{|B},{\cal A}_{|B})$ muss man also davon ausgehen, dass $B$
bereits eingetroffen ist.
Man liest $\Omega_{|B}$ auch als ``$\Omega$ bedingt $B$''.

Wenn nun auf $(\Omega, {\cal A})$ eine Wahrscheinlichkeitsfunktion $P$
gegeben ist, kann man auch $P_{|B}$ bilden, indem man setzt
\begin{equation*}
P_{|B}(A)=\frac{P(A\cap B)}{P(B)},
\end{equation*}
der Nenner $P(B)$ stellt dabei sicher, dass $P_{|B}(\Omega_{|B})=P_{|B}(B)=1$.

\begin{definition}
\label{def-bedingte-wahrscheinlichkeit}
Die bedingte Wahrscheinlichkeit eines Ereignisses $A$ unter der Bedingung
$B$ ist
\[
P(A|B)=\frac{P(A\cap B)}{P(B)}.
\]
Man liest dies auch als ``Wahrscheinlichkeit von $A$ bedingt $B$''.
\end{definition}

Auch hier w"are nachzupr"ufen, dass die Rechenregeln f"ur eine
Wahrscheinlichkeitsfunktion erf"ullt sind.
Um also die Wahrscheinlichkeit in dieser Welt zu berechnen,
in der $B$ bereits eingetroffen ist, 
muss man $P(A\cap B)$ berechnen k"onnen.
Dies sollte Motivation genug sein, Rechenregeln f"ur
$P(A\cap B)$ aufzustellen, die uns bisher fehlen.

\subsection{Wahrscheinlichkeit von \texorpdfstring{$A\cap B$}{A geschnitten B}}
\begin{figure}
\begin{center}
\includegraphics{images/abhaengigkeit-1}
\end{center}
\caption{Unabh"angige Ereignisse. Die Ereignisse sind so dargestellt,
dass ihre Wahrscheinlichkeit proportional zur Fl"ache ist. $P(A)$ und $P(B)$
entsprechen dem Teilverh"altnis, in dem $A$ bzw.~$B$ die Seite des grossen
Rechtecks teilen. $P(A\cap B)=P(A)\cdot P(B)$\label{unabhaengig}}
\end{figure}
\begin{figure}
\begin{center}
\includegraphics{images/abhaengigkeit-2}
\end{center}
\caption{Abh"angige Ereignisse. $P(A\cap B)$ ist offensichtlich viel kleiner
als $P(A)\cdot P(B)$. $A$ wird unwahrscheinlicher, wenn bereits $B$ eingetreten
ist.
\label{abhaengig}}
\end{figure}
Der Grund daf"ur, dass es keine einfache Rechenregel f"ur die Berechung von 
$P(A\cap B)$ aus $P(A)$ und $P(B)$ gibt, wird mit der
Visualisierung der Ereignisse im in einem Venn-Diagramm sofort klar.
Die Elementarereignisse seien so angeordnet, dass $A$ das durch eine
vertikale Strecke abgetrennte linke Teilrechteck von $\Omega$ ist. Ausserdem
sollen Sie so angeordnet sein, dass die Wahrscheinlichkeit dem
Fl"acheninhalt im Diagramm entspricht.

Das Ereignis $B$ ist jetzt im Allgemeinen eine Teilmenge, die sowohl $A$ 
als auch $\bar A$ schneidet. Die Wahrscheinlichkeit $P(A \cap B)$ entspricht
der Fl"ache der Schnittmenge im Diagramm. Im Allgemeinen haben wir
nur aus $P(B)$ nicht gen"ugend Information um zu entscheiden, welche
``Form'' $A\cap B$ hat, wir k"onnen also nicht erwarten, dass wir $P(A\cap B)$
berechnen k"onnen.

Wenn sich $B$ ebenfalls mittels einer horizontalen Strecke als Rechteck
einzeichnen l"asst, dann ist $P(B)$ auch das Teilverh"altnis, in dem
die Strecke die vertikale Kante des Diagrams teilt. Somit kann man $P(A\cap B)$
als Fl"acheninhalt des Schnittrechtecks berechnen: $P(A\cap B)=P(A)\cdot P(B)$.
Die Voraussetzung bedeutet, dass das Eintreffen von $B$ nicht wahrscheinlicher
oder weniger
wahrscheinlich wird, wenn $A$ eintrifft. Das Eintreffen von $B$ h"angt also
nicht mit dem Eintreffen von $A$ zusammen.

\begin{definition}
\label{def-unabhaengige-ereignisse}
Die Ereignisse $A$ und $B$ heissen {\em unabh"angig}, wenn gilt:
\[
P(A\cap B) = P(A)\cdot P(B).
\]
\end{definition}

Beim W"urfeln sagt die Erfahrung, dass sich ein W"urfel nicht an den
letzten Wurf erinnern kann, d.h. der Ausgang des letzten Wurfes hat
keinen Einfluss auf den n"achsten Wurf. Die Ereignisse ``im ersten
Wurf wird eine 5 gew"urfelt'' und ``im zweiten Wurf wird eine 6 gew"urfelt''
sind also unabh"angig. Die Wahrscheinlichkeit, dass mit einem W"urfel
erst eine 5, dann eine 6 gew"urfelt wird, ist also
\begin{align*}
P(A\cap B)&=P(\text{``erster Wurf: 5''}\cap\text{``zweiter Wurf: 6''})\\
&=P(\text{``erster Wurf: 5''})\cdot P(\text{``zweiter Wurf: 6''})\\
&=\frac1{36}.
\end{align*}

\subsection{Bedingte Wahrscheinlichkeit}
Im vorangegangenen Abschnitt wurde bereits die bedingte Wahrscheinlichkeit
$P_{|B}(A)$ konstruiert, die wir auch
\[
P(A|B)=\frac{P(A\cap B)}{P(B)}
\]
schreiben. Die Bedeutung des Symbols $P(A|B)$ ist die folgende. Bei der
Bestimmung der Wahrscheinlichkeit werden nur diejenigen Experimente
ber"ucksichtigt, bei denen das Ereignis $B$ eingetreten ist.
Alle anderen Experimente interessieren nicht.

\subsubsection{Beispiel: Autounf"alle und Alkohol}
Wenn jemand sagt, 50\%
der t"odlichen Autounf"alle geschehen unter Alkoholeinfluss, dann
meint er genau genommen eigentlich folgendes. Wir machen ein Experiment,
bei dem wir jeden Autounfall untersuchen. Das Ereignis $T$ umfasst alle
t"odlich ausgehenden Autounf"alle, das Ereignis $A$ all jene, bei denen
Alkohol im Spiel war. Uns interessieren jetzt nur noch die t"odlichen
Unf"alle, also die, bei denen das Ereignis $T$ eingetreten ist. 
Die anderen untersuchen wir gar nicht mehr. Jetzt m"ochten wir die
Wahrscheinlichkeit wissen, dass Alkohol im Spiel war, aber nur noch
bei den t"odlichen Unf"allen. Dies ist $P(A|T)$, also gilt
$P(A|T)=50\% = 0.5$.
$P(T|A)$ ist hingegen ganz etwas anderes. Hier fragt man danach,
wie wahrscheinlich es ist, dass bei einem Autounfall unter Alkoholeinfluss
ein Toter zu beklagen ist.

\subsubsection{Beispiel: Rauchen und Lungenkrebs}
\index{Rauchen}
\index{Lungenkrebs}
In einem Zeitungsartikel gefunden: Die Wahrscheinlichkeit, dass ein Raucher
Lungenkrebs entwickelt, ist 15\%, bei einem Nichtraucher ist sie nur 1\%.
Das Experiment besteht darin, einen Menschen zu beobachten. Einige
davon sind Raucher (Ereignis $R$), einige entwickeln Lungenkrebs (Ereignis $L$).
Betrachtet man nur die Raucher, so ist die Wahrscheinlichkeit f"ur
Lungenkrebs 15\%, also
\[
P(L|R)=0.15
\]
Betrachtet man nur die Nichtraucher, also das Ereignis $\bar R$, findet
man 
\[
P(L|\bar R)=0.01.
\]
Der Artikel liefert aber keine Auskunft dar"uber, wieviele der
lungenkrebskranken Raucher sind, denn das w"are die Wahrscheinlichkeit
$P(R|L)$.

\subsubsection{Zusammenhang zwischen \texorpdfstring{$P(A\cap B)$}{P(A geschnitten B)}, \texorpdfstring{$P(A|B)$}{P(A bedingt B)} und \texorpdfstring{$P(B|A)$}{P(B bedingt A)}}
In allen drei F"allen geht es um die Wahrscheinlichkeit des Eintretens
von $A$ und von $B$, allerdings jeweils in verschiedenem
Zusammenhang.
\begin{center}
\begin{tabular}{|c|l|c|}
\hline
Wahrscheinlichkeit&"Ubersetzung&Scope\\
\hline
$P(A\cap B)$&\strut Wahrscheinlichkeit, dass $A$ und $B$ eintreten\strut &$\Omega$\\
%\hline
$P(A|B)$&\begin{minipage}[t]{3.0in}\strut Wahrscheinlichkeit, dass $A$ eintritt, wenn $B$ schon eingetreten ist\strut \end{minipage}&$B$\\
%\hline
$P(B|A)$&\begin{minipage}[t]{3.0in}\strut Wahrscheinlichkeit, dass $B$ eintritt, wenn $A$ schon eingetreten ist\strut \end{minipage}&$A$\\
\hline
\end{tabular}
\end{center}
(Vergleiche auch Abbildung~\ref{condprob}.)
\begin{figure}
\begin{center}
\includegraphics[width=0.3\hsize]{images/abhaengigkeit-3}\quad
\includegraphics[width=0.3\hsize]{images/abhaengigkeit-5}\quad
\includegraphics[width=0.3\hsize]{images/abhaengigkeit-4}
\end{center}
\caption{Wahrscheinlichkeit von $A\cap B$ in jeweils anderer Umgebung
\label{condprob}}
\end{figure}

%\subsubsection{Technische Details}
%{\small
%In der Einleitung zu diesem Abschnitt wurde bereits die Konstruktion
%$(\Omega_{|B},{\cal A}_{|B})$ durchgef"uhrt, es ist aber notwendig
%nachzupr"ufen, dass dabei alles mit rechten Dingen zuging, und dass die
%dabei tats"achlich eine Ereignisalgebra konstruiert wurde, und im Falle von
%$P_{|B}$ eine Wahrscheinlichkeitsfunktion.
%
%\begin{satz} Ist $(\Omega,{\cal A})$ eine Ereignisalgebra und
%$B\in{\cal A}$ ein Ereignis, dann ist $(\Omega_{|B},{\cal A}_{|B})$
%eine Ereignisalgebra mit
%\begin{eqnarray*}
%\Omega_{|B}&=&B\\
%{\cal A}_{|B}&=&\{A\cap B\;|\;A\in{\cal A}\}.\\
%\end{eqnarray*}
%\end{satz}
%\begin{proof}[Beweis]
%Es muss nachgepr"uft werden, dass die Vereinigung und die
%Differenz von Ereignissen
%wieder ein Ereignis ist, und dass $\Omega_{|B}\in{\cal A}_{|B}$.
%Dazu bemerken wir zun"achst, dass die Mengen $A\cap B\in {\cal A}_{|B}$
%nat"urlich auch Ereignisse in ${\cal A}$ sind, denn Schnittmengen von
%Ereignissen sind ja wieder Ereignisse.
%
%Eine Folge von Ereignissen $B_i\in{\cal A}_{|B}$ ist also auch eine
%Folge von Ereignissen $B_i\in{\cal A}$, d.h. auch deren Vereinigung
%ist ein Ereignis in ${\cal A}$. Die Vereinigung ist aber auch eine Teilmenge
%von $B$, denn jede einzelne Menge ist darin enthalten. Somit ist
%$$\bigcup_{i=0}^{\infty}B_i=
%B\cap \bigcup_{i=0}^{\infty}B_i\in{\cal A}_{|B}.$$
%Analog folgt, dass mit $C,D\in{\cal A}_{|B}$ auch $C\setminus D$ in ${\cal A}$
%ist, aber auch $C\setminus D\subset B$,
%also $C\setminus D=B\cap(C\setminus D)\in{\cal A}_{|B}$.
%
%Wegen $B=\Omega\cap B\in{\cal A}_{|B}$ sind also alle Axiome erf"ullt.
%\end{proof}
%Zu einer Wahrscheinlichkeitsfunktion $P$ auf $(\Omega,{\cal A})$ haben wir
%bereits die eingeschr"ankte Wahrscheinlichkeitsfunktion $P_{|B}$ konstruiert,
%wir wollen jetzt nachweisen, dass diese die Axiome einer
%Wahrscheinlichkeitsfunktion erf"ullt:
%
%\begin{satz}
%Sei $P$ eine Wahrscheinlichkeitsfunktion auf $(\Omega, {\cal A})$, dann
%ist
%$$P_{|B}(A)=\frac{P(A\cap B)}{P(B)}$$
%eine Wahrscheinlichkeitsfunktion auf $(\Omega_{|B}, {\cal A}_{|B})$.
%\end{satz}
%
%\begin{proof}[Beweis]
%Es sind die drei Axiome f"ur eine Wahrscheinlichkeitsfunktion nachzupr"ufen.
%Sei also $A$ ein Ereignis mit $A\subset B$. Zun"achst zeigen wir, dass 
%$P(A)\le P(B)$. Dazu beachten wir, dass $B=A \cup (B\setminus A)$, wobei
%$A$ und $B\setminus A$ disjunkt sind. Also gilt
%$$P(A)+P(B\setminus A) = P(B).$$
%Da $P(B\setminus A)\ge 0$ folgt daraus $P(A) \le P(B)$.
%Aus dieser Ungleichung folgt jetzt
%$$0\le \frac{P(A)}{P(B)}\le \frac{P(B)}{P(B)}= 1,$$
%d.~h.~das Axiom "uber den Wertebereich ist erf"ullt.
%
%F"ur das sichere Ereignis $B$ in $(\Omega_{|B},{\cal A}_{|B})$ gilt
%$$P_{|B}(B)=\frac{P(B)}{P(B)}=1,$$
%d.~h.~das Axiom betreffend die Wahrscheinlichkeit des sicheren Ereignisses
%ist erf"ullt.
%
%Sei jetzt $A_i$ eine Folge von paarweise disjunkten Ereignissen, die alle
%in $B$ enthalten sind. Dann gilt
%$$P_{|B}\bigl(\bigcup_{i=0}^{\infty}A_i\bigr)
%=P\bigl(\bigcup_{i=0}^{\infty}A_i\bigr)
%=\sum_{i=0}^{\infty}P(A_i)
%=\sum_{i=0}^{\infty}P_{|B}(A_i),$$
%d.~h.~das Axiom betreffend die Vereinigung ist erf"ullt.
%\end{proof}
%
%Somit l"asst sich aus einer Ereignisalgebra und einer
%Wahrscheinlichkeitsfunktion zu einem Ereignis $B$ immer eine
%kleinere Ereignisalgebra bilden, in der das Ereignis $B$ immer
%eintritt. Die zugeh"orige Wahrscheinlichkeitsfunktion $P_{|B}$
%heisst bedingte Wahrscheinlichkeit:
%
%\begin{definition} Ist $(\Omega,{\cal A})$ eine Ereignisalgebra
%und $P$ eine Wahrscheinlichkeitsfunktion, dann heisst die
%Wahrscheinlichkeitsfunktion $P_{|B}$ auf $(\Omega_{|B}, {\cal A}_{|B})$,
%definiert durch
%$$P_{|B}(A)=P(A|B)=\frac{P(A\cap B)}{P(B)}$$
%die bedingte Wahrscheinlichkeit von $A$ unter der Voraussetzung, dass
%$B$ bereits eingetroffen ist.
%\end{definition}
%
%Sind $A$ und $B$ unabh"angige Ereignisse, dann gilt 
%$$P(A|B)=\frac{P(A\cap B)}{P(B)}=\frac{P(A)\cdot P(B)}{P(B)}=P(A),$$
%d.~h.~die Wahrscheinlichkeit, dass $A$ eintritt, ist genau gleich gross
%wie die Wahrscheinlichkeit, dass $A$ unter der Voraussetzung eintritt,
%dass $B$ bereits eingetreten ist. Ob $B$ eingetreten ist oder nicht,
%hat somit auf ein unabh"angiges Ereignis keinen Einfluss.
%
%Die
%\marginpar{\tiny experimentelle Bestimmung bedinger Wahrscheinlichkeiten}
%bedingten Wahrscheinlichkeiten sind das A und O von Meinungsumfragen.
%Bei einer Meinungsumfrage werden ausser der Frage nach der Meinung auch
%Fragen "uber die Person gestellt. Es wird also nicht nur die Wahrscheinlichkeit
%des Ereignises ``Person stimmt zu'' oder ``Person lehnt ab'' gesucht, sondern
%es ist auch die Wahrscheinlichkeit von ``Person ist zwischen 20 und 30 Jahre
%alt'', oder ``Person ist verheiratet'', oder ``Person ist fussballinteressiert''
%bekannt. Aber auch die bedingten Wahrscheinlichkeiten sind bekannt. Wenn
%man nur die Antworten der 20 bis 30 j"ahrigen anschaut, und die relative
%H"aufigkeit der ``Ja''-Antworten in dieser Gruppe bestimmt, hat man
%die bedingte Wahrscheinlichkeit f"ur ``Ja'' ermittelt unter der
%Vorbedingung, dass ``Person ist zwischen 20 und 30 Jahre alt'' bereits
%eingetreten ist.
%}

\subsection{Zerlegung eines Wahrscheinlichkeitsraumes}
Der
Begriff der bedingten Wahrscheinlichkeit erm"oglicht,
ein Wahrscheinlichkeitsproblem in m"oglicherweise einfachere, jedenfalls
kleinere Probleme zu zerlegen. Wenn bei einem Experiment zwei Zust"ande
eintreten, die sich gegenseitig ausschliessen, k"onnen wir die 
Wahrscheinlichkeit bestimmen, unter denen die weiteren Resultate
des Experiments eintreten, jedoch unter der Vorbedingung, dass einer
der benannten Zust"ande bereits eingetreten ist. Wenn wir nun auch
noch die Wahrscheinlichkeit jedes Zustandes kennen, m"usste es doch
m"oglich sein, auch die Wahrscheinlichkeit der weiteren Resultate zu
ermitteln.

Im obigen Beispiel der Meinungsumfrage ist anschaulich klar, dass man die
Wahrscheinlichkeit f"ur ``Ja'' berechnen kann, wenn man einerseits die
Wahrscheinlichkeit f"ur ``Ja'' in  jeder Altersklasse kennt, und andererseits
weiss, wie die Altersklassen in der Bev"olkerung verteilt sind.

\begin{figure}
\begin{center}
\includegraphics{images/total-1.pdf}
\end{center}
\caption{Wahrscheinlichkeitsraum $\Omega$, der sich in die in die
Ereignisse $B_1,B_2,\dots,B_n$ zerlegen l"asst.\label{zerlegung}}
\end{figure}
Wir versuchen, das etwas formaler zu schreiben
(siehe Abbildung \ref{zerlegung}):
Sind $B_i$ mit $1\le i$ paarweise
disjunkte Ereignisse
in einer Ereignisalgebra $(\Omega,{\cal A})$, f"ur welche ausserdem
gilt
\[
\bigcup_{i=0}^{n}B_i = \Omega,
\]
dann kann man die Wahrscheinlichkeit von $A$ aus den bedingten
Wahrscheinlichkeiten der Teile $A\cap B_i$ und $B_i$ wieder zusammensetzen.
Bekannt sind die Wahrscheinlichkeiten
$P(B_i)$, die Wahrscheinlichkeit der Zust"ande, und
$P(A|B_i)$, die Wahrscheinlichkeit, dass $A$ eintritt, unter der Bedingung
das $B_i$ bereits eingetreten ist.
Nach Definition ist $P(A|B_i)=P(A\cap B_i)/P(B_i)$, also
$P(A|B_i)\cdot P(B_i) = P(A\cap B_i)$. Die Vereinigung der Ereignisse
$A\cap B_i$ ist
\[
\bigcup_{i=0}^{n} A\cap B_i=A\cap\bigcup_{i=0}^{n}B_i=A,
\]
und die Mengen $A\cap B_i$ sind disjunkt. Also kann man die Summe ihrer
Wahrscheinlichkeiten mit der Additionsformel ausrechnen:
\[
\sum_{i=0}^{n}P(A\cap B_i)=P\biggl(\bigcup_{i=0}^{n}A\cap B_i\biggr)=P(A).
\]
Andererseits
haben wir oben bereits $P(A\cap B_i)$ bestimmt, wir k"onnen
also einsetzen und erhalten:
\[
P(A)=\sum_{i=0}^{n}P(A|B_i)\cdot P(B_i).
\]
Somit l"asst sich tats"achlich die Wahrscheinlichkeit eines Ereignisses
aus den bedingten Wahrscheinlichkeiten und den Wahrscheinlichkeiten
der Bedingungen errechnen. Wir fassen diese Erkenntnis in folgendem 
Satz zusammen.
\index{Wahrscheinlichkeit!totale}
\begin{satz}
Ist $B_i$ eine Folge paarweise disjunkter Mengen mit $\bigcup_{i=0}^{n}B_i=\Omega$, dann gilt f"ur jedes Ereignis $A$
\[
P(A)=\sum_{i=0}^{n}P(A|B_i)\cdot P(B_i).
\]
\end{satz}
Dieser Satz heisst auch der {\em Satz von der totalen Wahrscheinlichkeit},
da er die Wahrscheinlichkeit eines Ereignisses aus den bedingten
Wahrscheinlichkeiten unter verschiedenen Voraussetzungen und der
Wahrscheinlichkeit des Eintretens dieser Voraussetzungen rekonstruiert.
Dieser Satz ist die ``wahrscheinlichkeitstheoretisch Form einer
Fallunterscheidung'': man kennnt die F"alle $B_i$, und deren Wahrscheinlichkeit
$P(B_i)$, sowie die Wahrscheinlichkeit $P(A|B_i)$, dass $A$ im Falle 
$B_i$ eintritt. Die Formel "uber die totale Wahrscheinlichkeit
liefert daraus wieder $P(A)$.

Wir bemerken noch, dass es gar nicht unbedingt n"otig ist, dass die Mengen
$B_i$ ganz $\Omega$ aussch"opfen, es w"urde auch
gen"ugen, wenn die Wahrscheinlichkeit $0$ ist, dass $A$ eintritt
unter der Bedingung,
dass bereits $\bigcup_{i=0}^{n}B_i$ eingetreten ist.
F"ur den
Experimentator bedeutet das, dass er nur jene Vorbedingungen $B_i$
ber"ucksichtigen muss, unter denen sein Experiment ``funktioniert'',
alle anderen m"oglichen Zust"ande haben keinen Einfluss auf
die Wahrscheinlichkeit seiner Resultate. Man darf beim Experimentieren
also durchaus einzelne Resultate verwerfen, wenn man weiss, was man tut!

\subsubsection{Studienerfolg}
Die folgenden Zahlen sind erfunden, und dienen nur der Illustration
des Prinzips. Eine Statistik hat die Wahrscheinlichkeit f"ur den
Studienerfolg untersucht, und folgende Resultate erhalten.
Die Studierenden setzen sich zusammen aus 60\% BMS, 30\% Kantonssch"uler
und "Ubertritte von anderen Hochschulen. Die Wahrscheinlichkeit
das Studium erfolgreich abzuschliessen, ist f"ur BMS 80\%,
f"ur Kantonssch"uler 90\%, 85\% f"ur die "Ubertreter von anderen
Hochschule. Wie gross ist die Wahrscheinlichkeit f"ur den Studienerfolg?

$\Omega$ ist die Menge aller Studienversuche. 60\% davon bilden das
Ereigns $B$ bestehend aus Studienversuchen, die im Anschluss an die BMS
erfolgen. 30\% machen das Ereignis $K$ mit den Kanti-Abg"angern aus,
10\% das Ereignis $A$ mit "Ubertritten von anderen Hochschulen. Es ist
klar, dass 
\[
\Omega = B \cup K\cup A.
\]
Gefragt ist die Wahrscheinlichkeit des Ereignisses $E$, welches
die erfolgreich abgeschlossenen Studienversuche beinhaltet.
F"ur die Wahrscheinlichkeit gilt nach dem Satz "uber die totale
Wahrscheinlichkeit
\begin{align*}
P(E)&=P(E|B)P(B)+P(E|K)P(K)+P(E|A)P(A).
\\
    &= 80\%\cdot 60\%
     + 90\%\cdot 30\%
     + 85\%\cdot 10\%
\\
&=0.8\cdot 0.6 + 0.9 \cdot 0.3 + 0.85 \cdot 0.1 = 0.835
\end{align*}

\subsubsection{W"urfelspiel}
Wir betrachten nochmals das Beispiel W"urfeln mit zwei W"urfeln, wobei
bei einem Pasch im ersten Wurf noch genau einmal gew"urfelt wird. 
Wir m"ochten die Wahrscheinlichkeit berechnen, dass die totale Augensumme
mindestens 10 ist. Wir nennen dieses Ereignis $Z$.

Zun"achst kann man unterteilen in den Fall, dass im ersten Wurf
ein Pasch geworfen wird. Es gilt nach dem Satz "uber die totale
Wahrscheinlichkeit
\[
P(Z) = P(Z|P) P(P) + P(Z|\bar P) P(\bar P).
\]
Selbstverst"andlich ist $P(\bar P)=1-P(P)$, so dass man $P(Z)$ bereits
vereinfachen kann:
\[
P(Z) = P(Z|P) P(P) + P(Z|\bar P) (1-P(P)).
\]
Man kann aber das Ereignis $P$ noch weiter unterteilen in die
Ereignisse $P_k$, mit $1\le k\le 6$, also
\begin{align*}
P(P)&=
P(P_1)+
P(P_2)+
P(P_3)+
P(P_4)+
P(P_5)+
P(P_6)
\\
P(Z|P)
&=
P(Z|P_1)P(P_1|P)+
P(Z|P_2)P(P_2|P)+
P(Z|P_3)P(P_3|P)
\\
&\qquad +
P(Z|P_4)P(P_4|P)+
P(Z|P_5)P(P_5|P)+
P(Z|P_6)P(P_6|P)
\end{align*}
Die Ereignisse haben wir auch fr"uher schon untersucht, daraus kann
man einige Wahrscheinlichkeiten bereits ablesen:
\begin{align*}
P(Z|P_6)&=1\\
P(Z|P_5)&=1\\
P(Z|P_4)&=1
\end{align*}
denn in allen diesen F"allen erreicht man mit dem zweiten Wurf mit
Sicherheit zehn oder mehr.

\subsection{Ziegen und Autos} \label{ziegen:autos}
Marylin vos Savant hat in einer Kolumne ein Gedankenexperiment vorgstellt.
In einer Quiz-Show muss der Kandidat eine von drei T"uren w"ahlen, wobei
sich hinter einer der T"uren ein Auto versteckt, hinter den anderen zweien
ein Ziege. Das Ziel des Spiels ist, das Auto zu gewinnen. Nach der Wahl
durch den Kandidaten "offnet der Quizmaster eine der T"uren, hinter der sich
eine Ziege befindet, nicht aber die T"ur, die der Kandidat gew"ahlt hat.
Der Kandidat hat jetzt nochmals die M"oglichkeit, die T"ur zu wechseln.
Welche Strategie soll er w"ahlen. Bei der ersten Auswahl bleiben, oder
wechseln?

Um die Frage zu beantworten berechnen wir die Gewinnwahrscheinlichkeit
f"ur jede der Strategien. Zun"achst die ``Bleibe''-Strategie. Es ist die
Wahrscheinlichkeit f"ur einen Gewinn $P(G)$ auszurechnen. Hinter der zun"achst
gew"ahlten T"ur kann sich ein Auto (Ereignis $A$) befinden, oder eine Ziege
(Ereignis $Z$). Es ist nat"urlich $A\cap Z=\emptyset$ und $A\cup Z=\Omega$.
Also gilt
\begin{equation}
P(G)=P(G|A) P(A) + P(G|Z)P(Z).
\label{ziegenformel}
\end{equation}
Nat"urlich ist $P(A)=\frac13$ und $P(Z)=\frac23$.
$P(G|A)$ ist die Wahrscheinlichkeit mit der ``Bleibe''-Strategie zu
gewinnen, wenn hinter der zun"achst gew"ahlten T"ur ein Auto war: diese
ist nat"urlich 1. Ebenso verliert man mit Sicherheit, wenn hinter der
T"ur eine Ziege war: $P(G|Z)=0$, also
\[
P(G)=P(G|A)P(A)+P(G|Z)P(Z)=1\cdot \frac13 + 0\cdot\frac 23=\frac13.
\]

F"ur die ``Wechsel''-Strategie gilt nat"urlich auch die Formel
\ref{ziegenformel}, aber die bedingten Wahrscheinlichkeiten sind verschieden.
Wenn man ein Auto gew"ahlt hatte, und wechselt, verliert man, also $P(G|A)=0$.
Hat man ein Ziege erwischt, und wechselt, bekommt man das Auto, denn die
zweite Ziege kann man ja nicht erwischen, deren T"ur hat der Quiz-Master
ge"offnet. Also ist $P(G|Z)=1$. Somit folgt jetzt
\[
P(G)=P(G|A)P(A)+P(G|Z)P(Z)=0\cdot\frac13+1\cdot\frac23=\frac23.
\]
Mit der Wechselstrategie ist also die Wahrscheinlichkeit, zu gewinnen,
doppelt so gross, wechseln lohnt sich also auf jeden Fall.


\subsection{Wahrscheinlichkeitsvektoren und -matrizen}
Der Satz von der totalen Wahrscheinlichkeit kann auch in Matrixform
geschrieben werden:
\begin{align*}
P(A)&=P(A|B_1)P(B_1)+\dots+P(A|B_n)P(B_n)
=
\begin{pmatrix}
P(A|B_1)&\dots&P(A|B_2)
\end{pmatrix}
\begin{pmatrix}
P(B_1)\\\vdots\\P(B_n)
\end{pmatrix}
\end{align*}
Der Spaltenvektor
\[
\begin{pmatrix}
P(B_1)\\\vdots\\P(B_n)
\end{pmatrix}
\]
hat die Eigenschaften, dass alle seine Eintr"age zwischen $0$ und $1$
liegen, und ihre Summe $1$ gibt.
\index{Wahrscheinlichkeitsvektor}
Ein solcher Vektor heisst {\it Wahrscheinlichkeitsvektor}.

Die Matrizenschreibweise erlaubt, auch die totalen Wahrscheinlichkeiten
f"ur mehrere Ereignisse $A_1,\dots,A_m$ gleichzeitig zu berechnen:
\[
\begin{pmatrix}
P(A_1)\\
P(A_2)\\
\vdots\\
P(A_m)
\end{pmatrix}
=
\begin{pmatrix}
P(A_1|B_1) & P(A_1|B_2) & \dots &P(A_1|B_n)\\
P(A_2|B_1) & P(A_2|B_2) & \dots &P(A_2|B_n)\\
\vdots     & \vdots     & \ddots&\vdots\\
P(A_m|B_1) & P(A_m|B_2) & \dots &P(A_m|B_n)\\
\end{pmatrix}
\begin{pmatrix}
P(B_1)\\
P(B_2)\\
\vdots\\
P(B_n)
\end{pmatrix}
\]
Sind die Ereignisse $A_i$ ebenfalls paarweise disjunkt und decken ganz
$\Omega$ ab, dann sind auch die Spalten von der Matrix $(P(A_i|B_j))$
jeweils Wahrscheinlichkeitsvektoren. 
\index{Wahrscheinlichkeitsmatrix}
Eine solche Matrix heisst {\it Wahrscheinlichkeitsmatrix}.

\subsection{Satz von Bayes} \label{satz-von-bayes}
\index{Bayes, Satz von}
F"ur zwei beliebige Ereignisse mit $A$ und $B$ mit nicht verschwindender
Wahrscheinlichkeit gilt
\[
P(A|B)\cdot P(B)= P(A\cap B)=P(B|A)\cdot P(A),
\]
und es folgt
\[
P(A|B)=\frac{P(B|A)\cdot P(A)}{P(B)}.
\]
Dieser Zusammenhang ist bekannt als der Satz von Bayes:
\begin{satz}[Satz von Bayes]
F"ur zwei Ereignisse $A$ und $B$ mit $P(B)\ne0$ gilt
\[
P(A|B)=\frac{P(B|A)\cdot P(A)}{P(B)}.
\]
\end{satz}
Die Bedeutung dieses Satzes besteht darin, dass er die Schlussrichtung
umzukehren erlaubt. Die bedingte Wahrscheinlichkeit $P(A|B)$ ist ja die
Wahrscheinlichkeit, dass ein das Ereignis $A$ eintritt, wenn $B$ bereits
eingetreten ist. Sie erlaubt, eine Wette einzugehen, dass $A$ eintreten
wird, wenn $B$ bereits eingetreten ist. Der Satz von Bayes erm"oglicht
also, auch eine Wette f"ur $B$ einzugehen, wenn $A$ bereits eingetreten
ist.
Im Gegensatz zur Schlussweise in der Logik, die niemals umkehrbar ist,
kann man auf Wahrscheinlichkeiten basierende Schl"usse umkehren.

\subsubsection{Was bedeutet ein positiver HIV-Test?}
\begin{figure}
\begin{center}
\includegraphics[width=\hsize]{graphics/aids-300}
\end{center}
\caption{``Blick am Abend'' vom 12.~August 2008\label{aids}}
\end{figure}
Im ``Blick am Abend'' vom 12.~August 2008 erschien der Artikel in Abbildung 
\ref{aids} mit dem Titel ``Warum uns Wahrscheinlichkeiten verwirren''.
Darin ist von folgenden Ereignissen die Rede, die sich auf sich nicht riskant
verhaltende M"anner ($=\Omega$) beziehen.
\index{HIV-Test}
\begin{enumerate}
\item Ereignis $H$: Ein Mann ist HIV-infiziert.
\item Ereignis $T$: ein HIV-Test ergibt ein positives Resultat.
\end{enumerate}
Der Artikel teilt uns zudem ein paar Wahrscheinlichkeiten mit:
\begin{itemize}
\item HIV-Rate bei M"annern, die sich nicht riskant verhalten:
$P(H)=0.0001$.
\item Wahrscheinlichkeit, dass bei einer infizierten Person der Test
ein positives Resultat ergibt: $P(T|H)=0.999$.
\item Wahrscheinlichkeit, dass bei einer gesunden Person der Test negativ
ist: $P(\bar T|\bar H)=0.9999$.
\end{itemize}
Wie gross ist die Wahrscheinlichkeit, dass ein sich nicht riskant verhaltender
Mann tats"achlich HIV hat, wenn er einen positiven HIV-Test hat? Wie
gross ist $P(H|T)$?

Der Satz von Bayes liefert die Antwort:
\begin{equation}
P(H|T)=\frac{P(T|H)\cdot P(H)}{P(T)}
\label{aidsprobability}
\end{equation}
Darin sind fast alle Gr"ossen direkt aus dem Artikel ablesbar, nur $P(T)$ muss
noch bestimmt werden. Dazu dient der Satz "uber die totale Wahrscheinlichkeit,
den wir auf die Tatsache anwenden, dass ein sich nicht riskant verhaltender
Mann entweder HIV hat oder nicht: $\Omega=H\cup \bar H$.
\begin{align*}
P(T)
&=P(T|H)\cdot P(H)+P(T|\bar H)\cdot P(\bar H)\\
&=P(T|H)\cdot P(H)+(1-P(\bar T|\bar H))\cdot (1 - P(H))\\
&=0.999\cdot 0.0001+(1-0.9999)\cdot(1-0.0001)\\
&=0.00019989\simeq 0.0002
\end{align*}
Eingesetzt in (\ref{aidsprobability}) ergibt sich jetzt das Resultat
\[
P(H|T)=\frac{0.999\cdot 0.0001}{0.0002}=.4995\simeq 0.5
\]
oder mit anderen Worten, auch wenn der HIV-Test positiv ist, ist
die Wahrscheinlichkeit f"ur einen sich nicht riskant verhaltenden Mann,
tats"achlich HIV-infiziert zu sein, nur $50\%$.

%\subsubsection{Weitere Beispiele}
%Im Anhang \ref{spamfilter} wird als weiteres Anwendungsbeispiel ein Spamfilter
%beschrieben. Der Google Pagerank, beschrieben in Anhang \ref{pagerank},
%ist eine Anwendung der bedingten Wahrscheinlichkeit und des Satzes von
%der totalen Wahrscheinlichkeit auf Suchmaschinen.

%\subsection{Der Viterbi-Algorithmus}
%Wir stellen uns einen "Ubertragungskanal vor, der endlich viele
%verschiedene Symbole "ubertragen kann.
%In diskreten, mit nat"urlichen Zahlen numerierten Zeitschritten,
%werden Symbole $A_i$ "ubermittelt.
%Infolge Rauschens k"onnen
%die Symbole nicht immer zuverl"assig erkannt werden, sondern
%nur mit einer gewissen Wahrscheinlichkeit.  Es wird also im $k$-ten
%Schritt das Symbol $a_k$ erkannt. $P(a|A)$ ist die Wahrscheinlichkeit,
%dass $a$ erkannt wird wenn tats"achlich $A$ "ubermittelt wurde.
%
%Die "ubermittelten Zeichen sind nicht zuf"allig, vielmehr sind
%gewisse Abfolgen von Zeichen wahrscheinlicher als andere. Die
%Wahrscheinlichkeit, $P(A_k|A_{k-1})$ h"angt nur von den beiden
%Zeichen ab, die "ubermittelt wurden. 
%
%{\bf 1. Schritt:} Ein Zeichen ist "ubermittelt worden, und das Zeichen
%$a_1$ ist erkannt worden. Welches Zeichen wurde gesendet?
%
%Die Wahrscheinlichkeit, dass das Zeichen $a$ erkannt wird, wenn
%$A$ "ubermittelt wird, $P(a|A)$. Wir m"ochten aber
%die Wahrscheinlichkeit, dass $A$ gesendet wird, wenn $a$ erkannt worde
%ist, also $P(A|a)$. Nach dem Satz von Bayes
%ist
%$$P(A|a)=\frac{P(a|A)\cdot P(A)}{P(a)}$$
%Wenn wir annehmen, dass die "ubermittelten Zeichen genau gleich
%wahrscheinlich sind wie die erkannten Zeichen, der Erkennungsmechanismus
%also keine Zeichen bevorzugt, dann k"urzen sich die einfachen
%Wahrscheinlichkeiten weg, und wir bekommen 
%$$P(A|a)=P(a|A).$$
%Daraus k"onnen wir schliessen, dass das wahrscheinlichste "ubermittelte
%Zeichen $A$ jenes ist, f"ur welches $P(a|A)$ maximal wird.
%
%{\bf 2. Schritt: } Wir nehmen jetzt an, dass bereits $k-1$ Beobachtungen
%aufgezeichnet worden sind, und dass bereits berechnet wurde, mit
%welcher Wahrscheinlichkeit $P(A_{k-1})$
%die unter diesen Beobachtungen wahrscheinlichste
%Abfolge von gesendeten Zeichen mit $A_{k-1}$ endet.
%
%\begin{enumerate}
%\item Wahrscheinlichkeit, dass der wahrscheinlichste Pfad zu einem
%in $X$ enden Pfad fortgesetzt wird:
%$$P(X|A_{k-1}) P(A_{k-1}).$$
%\item Wahrscheinlichkeit, dass der nach $X$ fortgesetzte Pfad 
%als $a_k$ erkannt wird
%\begin{equation}
%P(a_k|X) P(X|A_{k-1}) P(A_{k-1})
%\label{viterbi}
%\end{equation}
%\item
%Die wahrscheinlichste Fortsetzung des Pfades unter Ber"ucksichtigung
%der neuen Beobachtung $a_k$ ist also jenes $X$, welches
%(\ref{viterbi})
%maximiert.
%\end{enumerate}
%
%Wir beschreiben, wie sich der Algorithmus f"ur 
%Symbole $A\in\{1,\dots,n\}$
%durch\-f"uhren l"asst.
%\begin{enumerate}
%\item Array {\tt p[n]} allozieren, er enth"alt die aktuellen Werte
%von $P(A_k)$.
%\item Beobachtung $a_1$ verwerten: setze 
%$$\text{\tt p[I]}= P(a_1|{\tt I})$$
%\item Der wahrscheinlichste Zustand unter den bisher erfolgten Beobachtungen
%ist dasjenige {\tt J}, welches {\tt p[J]} maximiert.
%\item \label{viterbiloop}Neue Beobachtung $a_k$: Berechne die Werte
%\begin{equation}
%P(a_k|{\tt I})
%\cdot
%P({\tt I}|{\tt J})
%\cdot
%\text{\tt p[J]}
%\label{viterbimax}
%\end{equation}
%\item Finde {\tt I} derart, dass (\ref{viterbimax}) maximal wird, setze
%${\tt J}={\tt I}$.
%\item Gehe zu Schritt \ref{viterbiloop}.
%\end{enumerate}
%Dieser Algorithmus findet also diejene Folge von Zeichen, die am besten
%zu den erkannten Zeichen ``passt''. Nicht immer findet er die
%richtige Folge von Zeichen, aber es ist sehr wahrscheinlich, dass er
%viele Zeichen hintereinander richtig erkennt, und damit verst"andliche
%S"atze oder Datenbl"ocke rekonstruieren kann.
%
%
%\section{Ein paar technische Details}
%Solange man mit endlichen oder diskreten Mengen arbeitet, ist jede beliebige
%Teilmenge ein mathematisch sinnvolles Ereignis.
%In einigen der oben diskutierten F"allen ist die Menge $\Omega$ aber sehr
%gross, meistens "uberabz"ahlbar. In diesen F"allen ist es etwas viel
%verlangt, wenn die Funktion $P$ f"ur jede beliebige Teilmenge  von $\Omega$
%definiert sein soll, und ausserdem noch alle Axiome erf"ullt sein sollen.
%In der Tat wurden pathologische Mengen gefunden, f"ur die die Additionsregel
%f"ur jede sinnvolle Definition von $P$ nicht erf"ullbar ist.
%
%Aus technischen mathematischen Gr"unden muss daher die Menge der Ereignisse
%eingeschr"ankt werden. Dabei m"ussen die Rechenregeln f"ur $P$ erhalten
%bleiben. Dazu muss die leere Menge, die ganze Menge, die Komplementmenge
%einer Menge und jede endliche Vereinigung und jeder endliche Durchschnitt
%von Ereignissen wieder ein Ereignis sein.
%
%Auch in der Analysis gibt man den Zahlenmengen eine zus"atzliche
%Struktur, um den Begriff des Grenzwertes exakt formulieren zu k"onnen.
%Man arbeitet dabei meist mit offenen Intervallen, also mit Mengen der Form
%$$U_\varepsilon(x) = \{ y\in\mathbb R\;|\; |x-y|<\varepsilon\}.$$
%Eine Folge $(a_n)_{n\in\mathbb N}$ konvergiert zum Beispiel gegen den Grenzwert
%$a$ wenn zu jedem $\varepsilon > 0$ ein $N$ existiert so dass
%$a_k\in U_\varepsilon(a)$ wenn nur $a > N$ ist. Oder eine Funktion $f$ ist
%im Punkt $x$ stetig,
%wenn f\"ur jedes $\varepsilon > 0$ ein $\delta > 0$ existert,
%so dass $f$ die Punkte, die gen"ugend nahe bei $x$ sind, auch  nahe an $f(x)$
%abbildet:
%$$f(U_\delta(x)) \subset U_\varepsilon(f(x)).$$
%Den $U_\varepsilon(x)$ ist gemeinsam, dass sie alle offene B"alle sind,
%d.h.~mit jedem Punkt ist auch ein kleiner Ball um den Punkt in der Menge
%enthalten. Es gibt nat"urlich noch viele weitere offene Mengen, durch
%Vereinigung und endliche Durchschnitte k"onnen aus bekannten offenen Menge
%weitere offene Mengen erzeugt werden.
%
%Man kann die Begriffe Grenzwert und Stetigkeit vollst"andig aufbauen, wenn
%man weiss, was ``nahe'' heissen soll. Man k"onnte dazu einen Abstandsbegriff
%definieren, und Mengen $U_\varepsilon(x)$ f"ur beliebige Mengen betrachten,
%in denen so ein Abstandsbegriff definiert ist. Es geht aber auch allgemeiner.
%Statt sich damit abzum"uhen, den Abstandsbegriff zu kl"aren, kann man auch
%einfach die Menge aller offenen Mengen festlegen. Konvergenz w"urde dann zum
%Beispiel so definiert: die Folge $(a_k)_{k\in\mathbb N}$ ist konvergent, wenn
%es zu jeder offenen, $a$ enthaltenden Menge $U\ni a$ ein $N(U)$ gibt
%sodass $a_k\in U$ sobald $k>N(U)$. Stetigkeit ist noch einfacher: die Funktion
%$f$ ist stetig, wenn f"ur jede offene Menge $U$ im Wertebereich die
%Urbildmenge $f^{-1}(U)$ im Definitionsbereich offen ist.
%
%W"ahrend ein Abstandsbegriff in den meisten Anwendungen durchaus kein
%un"uberwindliches Hindernis ist, f"allt uns in der Wahrscheinlichkeitsrechnung
%bereits die Beschreibung aller Elementarereignisse schwer. Darauf nun
%auch noch f"ur alle von der Anwendung suggerierten $P$ eine Menge von
%Teilmengen $\Omega$ zu finden, welche die Ereignisse beschreiben k"onnte,
%wird kaum einfacher sein. Daher gehen wir den umgekehrten Weg, und geben
%die Menge $\Omega$ vor, verlangen aber zus"atzliche Eigenschaften, die
%uns garantieren, dass wir mit den $P$ nach Regeln rechnen k"onnen, die uns
%plausibel und nat"urlich erscheinen.
%

